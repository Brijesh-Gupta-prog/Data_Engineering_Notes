{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hadoop Architecture\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook provides a deep dive into Hadoop's architecture, including YARN, HDFS, MapReduce, and the foundational research that led to Hadoop's development.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- YARN (Yet Another Resource Negotiator) architecture\n",
        "- HDFS (Hadoop Distributed File System) architecture\n",
        "- MapReduce programming model and framework\n",
        "- Google's contribution to Big Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hadoop Architecture: YARN\n",
        "\n",
        "### YARN (Yet Another Resource Negotiator)\n",
        "\n",
        "**YARN** is the Hadoop cluster operating system, popularly known as the **Hadoop Cluster Resource Manager**.\n",
        "\n",
        "### Three Main Components\n",
        "\n",
        "**1. Resource Manager (RM)**\n",
        "- **Location**: Master node\n",
        "- **Function**: \n",
        "  - Manages cluster resources\n",
        "  - Allocates resources to applications\n",
        "  - Coordinates with Node Managers\n",
        "- **Responsibilities**:\n",
        "  - Scheduler: Allocates resources to various applications\n",
        "  - Applications Manager: Manages application masters\n",
        "\n",
        "**2. Node Manager (NM)**\n",
        "- **Location**: Worker nodes (Worker Node 1, Worker Node 2, Worker Node 3, etc.)\n",
        "- **Function**:\n",
        "  - Monitors resource usage on each node\n",
        "  - Reports to Resource Manager\n",
        "  - Manages containers on the node\n",
        "- **Responsibilities**:\n",
        "  - Container lifecycle management\n",
        "  - Resource monitoring (CPU, memory, disk)\n",
        "\n",
        "**3. Application Master (AM)**\n",
        "- **Location**: Runs in a container on a worker node\n",
        "- **Function**:\n",
        "  - Manages the lifecycle of an application\n",
        "  - Requests resources from Resource Manager\n",
        "  - Coordinates with Node Managers\n",
        "- **Responsibilities**:\n",
        "  - Negotiates resources for the application\n",
        "  - Monitors application progress\n",
        "  - Handles application failures\n",
        "\n",
        "### YARN Architecture Diagram\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────┐\n",
        "│         Resource Manager (RM)           │\n",
        "│         (Master Node)                   │\n",
        "└─────────────────────────────────────────┘\n",
        "                    │\n",
        "        ┌───────────┼───────────┐\n",
        "        │           │           │\n",
        "┌───────▼───┐ ┌─────▼─────┐ ┌───▼──────┐\n",
        "│ Worker    │ │ Worker    │ │ Worker   │\n",
        "│ Node 1    │ │ Node 2    │ │ Node 3   │\n",
        "│           │ │           │ │          │\n",
        "│ Node      │ │ Node      │ │ Node     │\n",
        "│ Manager   │ │ Manager   │ │ Manager  │\n",
        "│           │ │           │ │          │\n",
        "│ App       │ │ App       │ │ App      │\n",
        "│ Master    │ │ Master    │ │ Master   │\n",
        "│ Container │ │ Container │ │ Container│\n",
        "└───────────┘ └───────────┘ └──────────┘\n",
        "```\n",
        "\n",
        "**Key Points:**\n",
        "- Application Master container runs your application code\n",
        "- Each application has its own Application Master\n",
        "- Application Master is present in a worker node\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hadoop Architecture: HDFS\n",
        "\n",
        "### HDFS (Hadoop Distributed File System)\n",
        "\n",
        "**HDFS** provides distributed storage on a Hadoop cluster.\n",
        "\n",
        "### Two Main Components\n",
        "\n",
        "**1. Name Node**\n",
        "- **Function**: Stores file metadata\n",
        "- **Metadata Information**:\n",
        "  - File name\n",
        "  - Directory location\n",
        "  - File size\n",
        "  - File blocks\n",
        "  - Block ID\n",
        "  - Block sequence\n",
        "  - Block location (which Data Node stores each block)\n",
        "\n",
        "**2. Data Node**\n",
        "- **Function**: Stores actual data blocks\n",
        "- **Responsibilities**:\n",
        "  - Store and retrieve data blocks\n",
        "  - Replicate blocks for fault tolerance\n",
        "  - Report block status to Name Node\n",
        "\n",
        "### How HDFS Works\n",
        "\n",
        "1. **File Storage**: Large files are split into blocks (typically 128MB or 256MB)\n",
        "2. **Replication**: Each block is replicated across multiple Data Nodes (default: 3 replicas)\n",
        "3. **Metadata**: Name Node maintains metadata about all files and blocks\n",
        "4. **Fault Tolerance**: If a Data Node fails, data can be retrieved from replicas\n",
        "\n",
        "### HDFS Architecture\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────┐\n",
        "│         Name Node                   │\n",
        "│    (File Metadata Storage)          │\n",
        "│  - File names                       │\n",
        "│  - Block locations                  │\n",
        "│  - Directory structure              │\n",
        "└─────────────────────────────────────┘\n",
        "            │\n",
        "    ┌───────┼───────┐\n",
        "    │       │       │\n",
        "┌───▼───┐ ┌─▼───┐ ┌─▼───┐\n",
        "│ Data  │ │Data │ │Data │\n",
        "│ Node 1│ │Node2│ │Node3│\n",
        "│       │ │     │ │     │\n",
        "│ Block │ │Block│ │Block│\n",
        "│ Repl. │ │Repl.│ │Repl.│\n",
        "└───────┘ └─────┘ └─────┘\n",
        "```\n",
        "\n",
        "**Key Features:**\n",
        "- **Fault Tolerance**: Data replicated across multiple nodes\n",
        "- **Scalability**: Add more Data Nodes to increase storage\n",
        "- **High Throughput**: Optimized for large file reads\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hadoop Architecture: MapReduce\n",
        "\n",
        "### MapReduce\n",
        "\n",
        "**MapReduce** is both a **programming model** and a **programming framework** for processing large datasets in parallel.\n",
        "\n",
        "### MapReduce Model\n",
        "\n",
        "The MapReduce model requires implementing logic in **two functions**:\n",
        "\n",
        "**1. Map Function**\n",
        "- **Input**: Reads a data block\n",
        "- **Process**: Applies logic at the block level\n",
        "- **Output**: Produces intermediate key-value pairs\n",
        "- **Characteristics**: \n",
        "  - Processes data in parallel across multiple nodes\n",
        "  - Each map task processes one block independently\n",
        "\n",
        "**2. Reduce Function**\n",
        "- **Input**: Receives map output (intermediate key-value pairs)\n",
        "- **Process**: Consolidates the results\n",
        "- **Output**: Final aggregated results\n",
        "- **Characteristics**:\n",
        "  - Groups data by key\n",
        "  - Performs aggregation operations (sum, count, average, etc.)\n",
        "\n",
        "### How MapReduce Works\n",
        "\n",
        "```\n",
        "Input Data Blocks\n",
        "    │\n",
        "    ├─ Block 1 ──► Map ──► (key1, value1)\n",
        "    │                    (key2, value2)\n",
        "    ├─ Block 2 ──► Map ──► (key1, value3)\n",
        "    │                    (key2, value4)\n",
        "    └─ Block 3 ──► Map ──► (key1, value5)\n",
        "                            (key2, value6)\n",
        "                                │\n",
        "                                ▼\n",
        "                        Shuffle & Sort\n",
        "                                │\n",
        "                                ▼\n",
        "                    ┌───────────┴───────────┐\n",
        "                    │                       │\n",
        "            Reduce (key1)            Reduce (key2)\n",
        "                    │                       │\n",
        "                    ▼                       ▼\n",
        "            (key1, aggregated)    (key2, aggregated)\n",
        "```\n",
        "\n",
        "### MapReduce Framework Implementation\n",
        "\n",
        "- **Hadoop MapReduce Framework**: Implements the MapReduce model\n",
        "- **YARN**: Manages resource allocation for MapReduce jobs\n",
        "- **HDFS**: Manages data blocks that MapReduce processes\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **Data Locality**: Map tasks run on nodes where data is stored (reduces network traffic)\n",
        "2. **Parallel Processing**: Multiple map and reduce tasks run simultaneously\n",
        "3. **Fault Tolerance**: Failed tasks are automatically retried\n",
        "4. **Scalability**: Can process petabytes of data across thousands of nodes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google's Contribution to Big Data\n",
        "\n",
        "Google faced the Big Data problem and tried to solve it by addressing four key areas:\n",
        "\n",
        "### 1. Data Collection and Ingestion\n",
        "- Efficiently collect data from various sources\n",
        "- Handle high-velocity data streams\n",
        "\n",
        "### 2. Data Storage and Management\n",
        "- Store massive volumes of data\n",
        "- Ensure reliability and fault tolerance\n",
        "\n",
        "### 3. Data Processing and Transformation\n",
        "- Process large datasets efficiently\n",
        "- Enable parallel processing\n",
        "\n",
        "### 4. Data Access and Retrieval\n",
        "- Fast data retrieval\n",
        "- Support for various access patterns\n",
        "\n",
        "### Google's Research Papers\n",
        "\n",
        "**1. Google File System (GFS) Whitepaper - 2003**\n",
        "- Introduced distributed file system architecture\n",
        "- Designed for large-scale distributed applications\n",
        "- Key concepts: Master/Chunk servers, replication, fault tolerance\n",
        "- **Impact**: Foundation for HDFS (Hadoop Distributed File System)\n",
        "\n",
        "**2. MapReduce Paper - 2004**\n",
        "- Introduced the MapReduce programming model\n",
        "- Simplified parallel and distributed computing\n",
        "- Key concepts: Map and Reduce functions, automatic parallelization\n",
        "- **Impact**: Foundation for Hadoop MapReduce\n",
        "\n",
        "### Open Source Development\n",
        "\n",
        "These Google research papers became the basis for the development of **open-source Hadoop**:\n",
        "- **2003**: Google File System paper published\n",
        "- **2004**: MapReduce paper published\n",
        "- **2006**: Apache Hadoop project started (inspired by Google's papers)\n",
        "- **2008**: Hadoop became a top-level Apache project\n",
        "\n",
        "**Key Insight**: Google's research demonstrated that distributed computing on commodity hardware could solve big data problems cost-effectively.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
