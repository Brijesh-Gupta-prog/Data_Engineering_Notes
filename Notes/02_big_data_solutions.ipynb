{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big Data Solutions\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook covers the solutions and approaches developed to address the Big Data problem, including platform requirements and the emergence of distributed systems.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- Big Data Platform Requirements\n",
        "- Monolithic vs Distributed Approaches\n",
        "- Introduction to Hadoop Platform\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Big Data Platform Requirements\n",
        "\n",
        "To address the Big Data problem, platforms need to meet the following requirements:\n",
        "\n",
        "### 1. Store High Volume of Data Arriving at High Velocity\n",
        "- Handle massive data ingestion rates\n",
        "- Scale storage capacity horizontally\n",
        "- Support real-time and batch data ingestion\n",
        "\n",
        "### 2. Accommodate Structured, Semi-Structured, and Unstructured Data\n",
        "- **Structured**: Tables, CSV files\n",
        "- **Semi-Structured**: JSON, XML, log files\n",
        "- **Unstructured**: Text, images, videos, documents\n",
        "- Schema-on-read capability (flexible schema)\n",
        "\n",
        "### 3. Process High Volume of Variety of Data at Higher Velocity\n",
        "- Distributed processing across multiple machines\n",
        "- Parallel processing capabilities\n",
        "- Support for both batch and streaming processing\n",
        "- Fault tolerance and reliability\n",
        "\n",
        "### Key Capabilities Needed:\n",
        "- **Scalability**: Horizontal scaling (add more machines)\n",
        "- **Fault Tolerance**: Continue operating despite failures\n",
        "- **Cost-Effectiveness**: Use commodity hardware\n",
        "- **Performance**: Fast processing of large datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two Approaches to Big Data Solution\n",
        "\n",
        "Based on **scalability, fault tolerance, and cost-effectiveness**, two primary approaches emerged:\n",
        "\n",
        "### 1. Monolithic Approach\n",
        "\n",
        "**Characteristics:**\n",
        "- **Massive Resources**: Single machine with high-end CPU, RAM, and Disk\n",
        "- **Scaling**: Vertical scaling (scale up - add more resources to single machine)\n",
        "- **Fault Tolerance**: Primary/Secondary configuration (backup systems)\n",
        "- **Cost**: Expensive (high-end hardware, specialized equipment)\n",
        "- **Limitations**: \n",
        "  - Limited by maximum hardware capacity\n",
        "  - Single point of failure\n",
        "  - High cost per unit of performance\n",
        "\n",
        "**Use Cases:**\n",
        "- Traditional enterprise systems\n",
        "- Legacy mainframe systems\n",
        "- Systems requiring extreme single-machine performance\n",
        "\n",
        "### 2. Distributed Approach\n",
        "\n",
        "**Characteristics:**\n",
        "- **Cluster**: Resource pool across multiple machines (CPU, RAM, Disk)\n",
        "- **Scaling**: Horizontal scaling (scale out - add more machines)\n",
        "- **Fault Tolerance**: Multifold fault tolerance (data replicated across nodes)\n",
        "- **Cost**: Economical (commodity hardware, cost-effective)\n",
        "- **Advantages**:\n",
        "  - Virtually unlimited scalability\n",
        "  - High fault tolerance (no single point of failure)\n",
        "  - Cost-effective (use commodity hardware)\n",
        "  - Better resource utilization\n",
        "\n",
        "**Use Cases:**\n",
        "- Modern big data platforms (Hadoop, Spark)\n",
        "- Cloud-based systems\n",
        "- Large-scale data processing\n",
        "\n",
        "### Comparison\n",
        "\n",
        "| Aspect | Monolithic | Distributed |\n",
        "|--------|-----------|-------------|\n",
        "| **Scaling** | Vertical (Scale Up) | Horizontal (Scale Out) |\n",
        "| **Fault Tolerance** | Primary/Secondary | Multi-node replication |\n",
        "| **Cost** | Expensive | Economical |\n",
        "| **Scalability Limit** | Hardware maximum | Virtually unlimited |\n",
        "| **Resource Utilization** | Single machine | Multiple machines |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hadoop: Distributed Big Data Processing Platform\n",
        "\n",
        "**Hadoop** emerged as a distributed Big Data Processing Platform, addressing the limitations of traditional systems.\n",
        "\n",
        "### What is Hadoop?\n",
        "\n",
        "Hadoop is a distributed data processing platform that offers the following core capabilities:\n",
        "\n",
        "**1. YARN (Yet Another Resource Negotiator)**\n",
        "- Cluster resource manager\n",
        "- Acts as the Hadoop cluster operating system\n",
        "\n",
        "**2. HDFS (Hadoop Distributed File System)**\n",
        "- Distributed storage system\n",
        "- Stores data across multiple machines in a cluster\n",
        "\n",
        "**3. MapReduce**\n",
        "- Distributed computing framework\n",
        "- Processes data in parallel across the cluster\n",
        "\n",
        "### Hadoop Ecosystem\n",
        "\n",
        "Hadoop includes a rich ecosystem of tools:\n",
        "\n",
        "| Tool | Purpose |\n",
        "|------|---------|\n",
        "| **Hive** | SQL-like interface for querying data stored in Hadoop |\n",
        "| **Apache HBase** | NoSQL database for real-time read/write access |\n",
        "| **Sqoop** | Tool for transferring data between Hadoop and relational databases |\n",
        "| **Pig** | High-level scripting language for creating MapReduce programs |\n",
        "| **Oozie** | Workflow scheduler for managing Hadoop jobs |\n",
        "\n",
        "### Database vs Hadoop\n",
        "\n",
        "| Feature | Database | Hadoop |\n",
        "|---------|----------|--------|\n",
        "| **Data Storage** | Structured storage | Distributed storage (HDFS) |\n",
        "| **Query Language** | SQL | Hive SQL Query Language |\n",
        "| **Scripting Language** | PL/SQL | Pig Scripting Language |\n",
        "| **Programming Interface** | JDBC, ODBC | Programming language interface (Java, Python, etc.) |\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
