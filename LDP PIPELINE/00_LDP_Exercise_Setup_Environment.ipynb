{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3920f391-550b-463d-a124-1609d2a90b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup Environment for Lakeflow Declarative Pipeline Exercise\n",
    "\n",
    "This notebook sets up the environment for the Lakeflow Declarative Pipeline exercise.\n",
    "\n",
    "It will:\n",
    "- Create catalog: `ldp_exercise`\n",
    "- Create schema: `exercise_schema`\n",
    "- Create volume: `raw` within the schema\n",
    "- Create folders (orders, customers, products, payments) in the volume\n",
    "- Generate sample data files with **intentional data quality issues** for students to resolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3906cc26-4049-47dc-8d51-897e8b82e96a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba59641-783f-4842-968e-4457d3a8166c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define catalog, schema, and volume names\n",
    "CATALOG_NAME = 'ldp_exercise'\n",
    "SCHEMA_NAME = 'exercise_schema'\n",
    "VOLUME_NAME = 'raw'\n",
    "\n",
    "# Define the base volume path\n",
    "VOLUME_PATH = f'/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}'\n",
    "\n",
    "print(f'Catalog: {CATALOG_NAME}')\n",
    "print(f'Schema: {SCHEMA_NAME}')\n",
    "print(f'Volume: {VOLUME_NAME}')\n",
    "print(f'Volume Path: {VOLUME_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c6d42fa-27a6-417d-b246-3b77eff2919b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Create Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9be29a2-05ac-488f-9941-bf439c530349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create catalog if it doesn't exist\n",
    "CREATE CATALOG IF NOT EXISTS ldp_exercise;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6f0b7d5-216e-4c3d-b9a9-ca46aec4d326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c16139-c8d2-4432-b188-c6b15fbc0a30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create schema within the catalog\n",
    "CREATE SCHEMA IF NOT EXISTS ldp_exercise.exercise_schema;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac23baa5-8eb0-4b93-99d6-196005d30d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Create Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d173b5b-2c5d-425a-8158-bf1b827e32fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create volume within the schema\n",
    "CREATE VOLUME IF NOT EXISTS ldp_exercise.exercise_schema.raw;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11057c11-9e84-499b-b32a-0b1b6dd5df2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Create Directories in Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22811819-bdbc-4b7f-a8a8-916ab48be40e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_directory_in_volume(volume_path: str, folder_names: list):\n",
    "    '''\n",
    "    Creates multiple directories in the specified volume path using dbutils.fs.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume_path (str): The base volume path\n",
    "    - folder_names (list): A list of folder names to create\n",
    "    '''\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    for folder in folder_names:\n",
    "        folder_path = f'{volume_path}/{folder}'\n",
    "        try:\n",
    "            # Try to list the directory to check if it exists\n",
    "            dbutils.fs.ls(folder_path)\n",
    "            print(f'Directory {folder_path} already exists. No action taken.')\n",
    "        except:\n",
    "            # Directory doesn't exist, create it\n",
    "            dbutils.fs.mkdirs(folder_path)\n",
    "            print(f'Creating folder: {folder_path}')\n",
    "    print('----------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Create folders for orders, customers, products, and payments\n",
    "create_directory_in_volume(VOLUME_PATH, ['orders', 'customers', 'products', 'payments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9c17a3f-91b3-43d8-933b-10ae58be140b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Delete Existing Files (if resetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d693af86-0ec3-43d6-95ab-100cd3e4cf2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def delete_source_files(source_path: str):\n",
    "    \"\"\"\n",
    "    Deletes all files in the specified source volume.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_path: The path to the volume containing the files to delete\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    print(f'\\nSearching for files in {source_path} to delete...')\n",
    "    try:\n",
    "        files = dbutils.fs.ls(source_path)\n",
    "        file_list = [f.path for f in files if not f.isDir()]\n",
    "        if not file_list:\n",
    "            print(f'No files found in {source_path}.\\n')\n",
    "        else:\n",
    "            for file_path in file_list:\n",
    "                print(f'Deleting file: {file_path}')\n",
    "                dbutils.fs.rm(file_path)\n",
    "    except Exception as e:\n",
    "        print(f'Directory {source_path} does not exist or is empty: {e}')\n",
    "\n",
    "# Delete existing files if resetting\n",
    "delete_source_files(f'{VOLUME_PATH}/orders/')\n",
    "delete_source_files(f'{VOLUME_PATH}/customers/')\n",
    "delete_source_files(f'{VOLUME_PATH}/products/')\n",
    "delete_source_files(f'{VOLUME_PATH}/payments/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f6cc885-e724-4c0a-b824-8af45ad3fd81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 7: Generate Sample Data with Data Quality Issues\n",
    "\n",
    "This step creates sample JSON files with **intentional data quality issues** that students must resolve:\n",
    "\n",
    "- **Duplicates**: Some records appear multiple times\n",
    "- **Missing Values**: NULL values in critical fields\n",
    "- **Invalid Formats**: Incorrect date formats, invalid email addresses, negative prices\n",
    "- **Data Type Issues**: Numbers stored as strings, dates as strings in wrong format\n",
    "- **Inconsistent Data**: Mixed case values, inconsistent state codes\n",
    "- **Orphaned Records**: References to non-existent entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6d5c76d-3b9a-42da-8975-4149fd6da154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_sample_data_with_issues():\n",
    "    \"\"\"\n",
    "    Create sample JSON files with intentional data quality issues.\n",
    "    \n",
    "    Data includes:\n",
    "    - Orders: ~500 records with duplicates, missing values, invalid dates\n",
    "    - Customers: ~200 records with invalid emails, missing addresses, duplicates\n",
    "    - Products: ~100 records with negative prices, missing categories, invalid SKUs\n",
    "    - Payments: ~600 records with invalid amounts, missing order references, duplicate transactions\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    print(\"\\n----------------Creating sample JSON files with data quality issues----------------\")\n",
    "    \n",
    "    # Base date for generating timestamps\n",
    "    base_date = datetime(2024, 1, 1, 10, 0, 0)\n",
    "    \n",
    "    # ========== PRODUCTS DATA ==========\n",
    "    print(\"\\nðŸ“¦ Generating products data...\")\n",
    "    categories = ['Electronics', 'Clothing', 'Home & Garden', 'Books', 'Sports', 'Toys', 'Food', 'Beauty']\n",
    "    product_names = [\n",
    "        'Laptop Pro 15', 'Wireless Mouse', 'Mechanical Keyboard', 'USB-C Cable',\n",
    "        'T-Shirt Classic', 'Jeans Denim', 'Sneakers Sport', 'Winter Jacket',\n",
    "        'Coffee Maker', 'Blender Mix', 'Lamp Desk', 'Plant Pot',\n",
    "        'Python Guide', 'Data Science Book', 'Novel Fiction', 'Cookbook Recipes',\n",
    "        'Basketball', 'Yoga Mat', 'Dumbbells Set', 'Running Shoes',\n",
    "        'Action Figure', 'Board Game', 'Puzzle 1000', 'LEGO Set'\n",
    "    ]\n",
    "    \n",
    "    sample_products = []\n",
    "    for i in range(100):\n",
    "        product_id = 1000 + i\n",
    "        name = random.choice(product_names)\n",
    "        \n",
    "        # Issue: Some products have missing category (NULL)\n",
    "        category = random.choice(categories) if random.random() > 0.15 else None\n",
    "        \n",
    "        # Issue: Some prices are negative or zero\n",
    "        if random.random() < 0.1:\n",
    "            price = round(random.uniform(-50, 0), 2)  # Negative price\n",
    "        elif random.random() < 0.05:\n",
    "            price = 0  # Zero price\n",
    "        else:\n",
    "            price = round(random.uniform(10, 500), 2)\n",
    "        \n",
    "        # Issue: Some SKUs are invalid (empty or malformed)\n",
    "        if random.random() < 0.1:\n",
    "            sku = \"\"  # Empty SKU\n",
    "        elif random.random() < 0.05:\n",
    "            sku = f\"INVALID-{product_id}\"  # Invalid format\n",
    "        else:\n",
    "            sku = f\"SKU-{product_id:04d}\"\n",
    "        \n",
    "        # Issue: Stock quantity sometimes negative\n",
    "        stock_quantity = random.randint(-10, 100) if random.random() < 0.1 else random.randint(0, 100)\n",
    "        \n",
    "        sample_products.append({\n",
    "            \"product_id\": product_id,\n",
    "            \"name\": name,\n",
    "            \"category\": category,\n",
    "            \"price\": price,\n",
    "            \"sku\": sku,\n",
    "            \"stock_quantity\": stock_quantity,\n",
    "            \"created_at\": (base_date + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "        })\n",
    "    \n",
    "    # ========== CUSTOMERS DATA ==========\n",
    "    print(\"ðŸ‘¥ Generating customers data...\")\n",
    "    first_names = [\"John\", \"Jane\", \"Bob\", \"Alice\", \"Charlie\", \"Diana\", \"Eve\", \"Frank\", \"Grace\", \"Henry\",\n",
    "                   \"Ivy\", \"Jack\", \"Kate\", \"Liam\", \"Mary\", \"Noah\", \"Olivia\", \"Paul\", \"Quinn\", \"Rachel\"]\n",
    "    last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\"]\n",
    "    states = [\"NY\", \"CA\", \"TX\", \"FL\", \"IL\", \"PA\", \"OH\", \"GA\", \"NC\", \"MI\"]\n",
    "    \n",
    "    sample_customers = []\n",
    "    customer_ids_used = set()\n",
    "    \n",
    "    for i in range(200):\n",
    "        customer_id = 2000 + i\n",
    "        first_name = random.choice(first_names)\n",
    "        last_name = random.choice(last_names)\n",
    "        name = f\"{first_name} {last_name}\"\n",
    "        \n",
    "        # Issue: Some emails are invalid or missing\n",
    "        if random.random() < 0.1:\n",
    "            email = None  # Missing email\n",
    "        elif random.random() < 0.1:\n",
    "            email = f\"invalid-email-{customer_id}\"  # Invalid email (no @)\n",
    "        elif random.random() < 0.05:\n",
    "            email = f\"{first_name.lower()}.{last_name.lower()}@\"  # Incomplete email\n",
    "        else:\n",
    "            email = f\"{first_name.lower()}.{last_name.lower()}{i}@example.com\"\n",
    "        \n",
    "        # Issue: Some addresses are missing\n",
    "        if random.random() < 0.15:\n",
    "            address = None\n",
    "            city = None\n",
    "            state = None\n",
    "            zip_code = None\n",
    "        else:\n",
    "            address = f\"{random.randint(100, 9999)} Main St\"\n",
    "            city = random.choice([\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\"])\n",
    "            # Issue: Some states are lowercase or invalid\n",
    "            if random.random() < 0.1:\n",
    "                state = random.choice(states).lower()  # Lowercase state\n",
    "            elif random.random() < 0.05:\n",
    "                state = \"XX\"  # Invalid state code\n",
    "            else:\n",
    "                state = random.choice(states)\n",
    "            zip_code = f\"{random.randint(10000, 99999)}\"\n",
    "        \n",
    "        # Issue: Some phone numbers are invalid\n",
    "        if random.random() < 0.1:\n",
    "            phone = None\n",
    "        elif random.random() < 0.1:\n",
    "            phone = \"123\"  # Too short\n",
    "        else:\n",
    "            phone = f\"{random.randint(200, 999)}-{random.randint(100, 999)}-{random.randint(1000, 9999)}\"\n",
    "        \n",
    "        sample_customers.append({\n",
    "            \"customer_id\": customer_id,\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"address\": address,\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"zip_code\": zip_code,\n",
    "            \"phone\": phone,\n",
    "            \"created_at\": (base_date + timedelta(days=i%30)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        })\n",
    "        customer_ids_used.add(customer_id)\n",
    "    \n",
    "    # Issue: Add duplicate customers (same customer_id with different data)\n",
    "    for _ in range(10):\n",
    "        dup_customer = random.choice(sample_customers).copy()\n",
    "        dup_customer[\"created_at\"] = (base_date + timedelta(days=random.randint(100, 200))).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        sample_customers.append(dup_customer)\n",
    "    \n",
    "    # ========== ORDERS DATA ==========\n",
    "    print(\"ðŸ›’ Generating orders data...\")\n",
    "    order_statuses = ['pending', 'processing', 'shipped', 'delivered', 'cancelled', 'returned']\n",
    "    \n",
    "    sample_orders = []\n",
    "    order_ids_used = set()\n",
    "    \n",
    "    for i in range(500):\n",
    "        order_id = 50000 + i\n",
    "        \n",
    "        # Issue: Some orders reference non-existent customers\n",
    "        if random.random() < 0.05:\n",
    "            customer_id = random.randint(5000, 6000)  # Non-existent customer\n",
    "        else:\n",
    "            customer_id = random.choice(list(customer_ids_used))\n",
    "        \n",
    "        # Issue: Some timestamps are in wrong format or invalid\n",
    "        if random.random() < 0.1:\n",
    "            order_date = (base_date + timedelta(days=random.randint(0, 365), hours=random.randint(0, 23))).strftime(\"%d/%m/%Y %H:%M\")  # Wrong format\n",
    "        elif random.random() < 0.05:\n",
    "            order_date = \"invalid-date\"  # Invalid date\n",
    "        else:\n",
    "            order_date = (base_date + timedelta(days=random.randint(0, 365), hours=random.randint(0, 23))).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        \n",
    "        # Issue: Some statuses are invalid or missing\n",
    "        if random.random() < 0.1:\n",
    "            status = None  # Missing status\n",
    "        elif random.random() < 0.05:\n",
    "            status = \"INVALID_STATUS\"  # Invalid status\n",
    "        else:\n",
    "            status = random.choice(order_statuses)\n",
    "        \n",
    "        # Issue: Some totals are negative or missing\n",
    "        if random.random() < 0.1:\n",
    "            total_amount = round(random.uniform(-100, 0), 2)  # Negative total\n",
    "        elif random.random() < 0.05:\n",
    "            total_amount = None  # Missing total\n",
    "        else:\n",
    "            total_amount = round(random.uniform(20, 1000), 2)\n",
    "        \n",
    "        sample_orders.append({\n",
    "            \"order_id\": order_id,\n",
    "            \"customer_id\": customer_id,\n",
    "            \"order_date\": order_date,\n",
    "            \"status\": status,\n",
    "            \"total_amount\": total_amount\n",
    "        })\n",
    "        order_ids_used.add(order_id)\n",
    "    \n",
    "    # Issue: Add duplicate orders\n",
    "    for _ in range(20):\n",
    "        dup_order = random.choice(sample_orders).copy()\n",
    "        sample_orders.append(dup_order)\n",
    "    \n",
    "    # ========== PAYMENTS DATA ==========\n",
    "    print(\"ðŸ’³ Generating payments data...\")\n",
    "    payment_methods = ['credit_card', 'debit_card', 'paypal', 'bank_transfer', 'cash']\n",
    "    payment_statuses = ['pending', 'completed', 'failed', 'refunded']\n",
    "    \n",
    "    sample_payments = []\n",
    "    \n",
    "    for i in range(600):\n",
    "        payment_id = 70000 + i\n",
    "        \n",
    "        # Issue: Some payments reference non-existent orders\n",
    "        if random.random() < 0.08:\n",
    "            order_id = random.randint(60000, 70000)  # Non-existent order\n",
    "        else:\n",
    "            order_id = random.choice(list(order_ids_used))\n",
    "        \n",
    "        # Issue: Some amounts are negative, zero, or missing\n",
    "        if random.random() < 0.1:\n",
    "            amount = round(random.uniform(-200, 0), 2)  # Negative amount\n",
    "        elif random.random() < 0.05:\n",
    "            amount = 0  # Zero amount\n",
    "        elif random.random() < 0.05:\n",
    "            amount = None  # Missing amount\n",
    "        else:\n",
    "            amount = round(random.uniform(10, 1200), 2)\n",
    "        \n",
    "        # Issue: Some payment methods are invalid\n",
    "        if random.random() < 0.1:\n",
    "            payment_method = None  # Missing method\n",
    "        elif random.random() < 0.05:\n",
    "            payment_method = \"INVALID_METHOD\"  # Invalid method\n",
    "        else:\n",
    "            payment_method = random.choice(payment_methods)\n",
    "        \n",
    "        # Issue: Some statuses are invalid\n",
    "        if random.random() < 0.1:\n",
    "            payment_status = None  # Missing status\n",
    "        elif random.random() < 0.05:\n",
    "            payment_status = \"UNKNOWN\"  # Invalid status\n",
    "        else:\n",
    "            payment_status = random.choice(payment_statuses)\n",
    "        \n",
    "        # Issue: Some timestamps are in wrong format\n",
    "        if random.random() < 0.1:\n",
    "            payment_date = (base_date + timedelta(days=random.randint(0, 365), hours=random.randint(0, 23))).strftime(\"%m-%d-%Y\")  # Wrong format\n",
    "        else:\n",
    "            payment_date = (base_date + timedelta(days=random.randint(0, 365), hours=random.randint(0, 23))).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        \n",
    "        sample_payments.append({\n",
    "            \"payment_id\": payment_id,\n",
    "            \"order_id\": order_id,\n",
    "            \"amount\": amount,\n",
    "            \"payment_method\": payment_method,\n",
    "            \"payment_status\": payment_status,\n",
    "            \"payment_date\": payment_date\n",
    "        })\n",
    "    \n",
    "    # Issue: Add duplicate payments\n",
    "    for _ in range(30):\n",
    "        dup_payment = random.choice(sample_payments).copy()\n",
    "        sample_payments.append(dup_payment)\n",
    "    \n",
    "    # Write files using dbutils.fs.put (newline-delimited JSON)\n",
    "    try:\n",
    "        # Products file\n",
    "        products_file = f'{VOLUME_PATH}/products/00.json'\n",
    "        products_json_lines = [json.dumps(product) for product in sample_products]\n",
    "        products_content = '\\n'.join(products_json_lines)\n",
    "        dbutils.fs.put(products_file, products_content, overwrite=True)\n",
    "        print(f'âœ… Created products file: {products_file} ({len(sample_products)} records)')\n",
    "        \n",
    "        # Customers file\n",
    "        customers_file = f'{VOLUME_PATH}/customers/00.json'\n",
    "        customers_json_lines = [json.dumps(customer) for customer in sample_customers]\n",
    "        customers_content = '\\n'.join(customers_json_lines)\n",
    "        dbutils.fs.put(customers_file, customers_content, overwrite=True)\n",
    "        print(f'âœ… Created customers file: {customers_file} ({len(sample_customers)} records)')\n",
    "        \n",
    "        # Orders file\n",
    "        orders_file = f'{VOLUME_PATH}/orders/00.json'\n",
    "        orders_json_lines = [json.dumps(order) for order in sample_orders]\n",
    "        orders_content = '\\n'.join(orders_json_lines)\n",
    "        dbutils.fs.put(orders_file, orders_content, overwrite=True)\n",
    "        print(f'âœ… Created orders file: {orders_file} ({len(sample_orders)} records)')\n",
    "        \n",
    "        # Payments file\n",
    "        payments_file = f'{VOLUME_PATH}/payments/00.json'\n",
    "        payments_json_lines = [json.dumps(payment) for payment in sample_payments]\n",
    "        payments_content = '\\n'.join(payments_json_lines)\n",
    "        dbutils.fs.put(payments_file, payments_content, overwrite=True)\n",
    "        print(f'âœ… Created payments file: {payments_file} ({len(sample_payments)} records)')\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error creating sample files: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Create sample JSON files with data quality issues\n",
    "print('\\nðŸ“ Creating sample JSON files with intentional data quality issues...')\n",
    "sample_created = create_sample_data_with_issues()\n",
    "\n",
    "if sample_created:\n",
    "    print('\\nâœ… Successfully created all sample JSON files!')\n",
    "    print(f'\\nFiles created in: {VOLUME_PATH}')\n",
    "    print('  - products/00.json (~100 products with data issues)')\n",
    "    print('  - customers/00.json (~210 customers with data issues)')\n",
    "    print('  - orders/00.json (~520 orders with data issues)')\n",
    "    print('  - payments/00.json (~630 payments with data issues)')\n",
    "    print('\\nâš ï¸  Note: These files contain intentional data quality issues that you must resolve!')\n",
    "else:\n",
    "    print('\\nâŒ Could not create sample files automatically.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b05adcd6-9782-4298-95a5-cea35259ade5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 8: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49087e51-32eb-4279-8d38-f4a3006940e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify catalog exists\n",
    "SHOW CATALOGS LIKE 'ldp_exercise';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c42e34f3-7b6a-4753-b432-3c7f5473b8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify schema exists\n",
    "SHOW SCHEMAS IN ldp_exercise LIKE 'exercise_schema';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e21931-bdf2-45a3-9c55-d8a44e84636e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify volume exists\n",
    "SHOW VOLUMES IN ldp_exercise.exercise_schema LIKE 'raw';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e90e7958-c312-4c78-b5f2-04387e5c09c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify folders and files\n",
    "print(f'\\nVerifying volume structure:')\n",
    "print(f'Volume path: {VOLUME_PATH}')\n",
    "print(f'\\nFolders:')\n",
    "for folder in ['orders', 'customers', 'products', 'payments']:\n",
    "    folder_path = f'{VOLUME_PATH}/{folder}'\n",
    "    try:\n",
    "        files = dbutils.fs.ls(folder_path)\n",
    "        file_list = [f.name for f in files if not f.isDir()]\n",
    "        print(f'  {folder}/: {len(file_list)} file(s)')\n",
    "        if file_list:\n",
    "            for file in sorted(file_list)[:3]:  # Show first 3 files\n",
    "                print(f'    - {file}')\n",
    "    except Exception as e:\n",
    "        print(f'  {folder}/: NOT FOUND or ERROR - {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "220aebb5-9002-4d77-b673-d2b9a332c699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup Complete!\n",
    "\n",
    "Your environment is now configured with:\n",
    "- Catalog: `ldp_exercise`\n",
    "- Schema: `exercise_schema`\n",
    "- Volume: `raw` at `/Volumes/ldp_exercise/exercise_schema/raw`\n",
    "- Folders: `orders`, `customers`, `products`, `payments`\n",
    "\n",
    "All tables will be created in the `ldp_exercise.exercise_schema` schema.\n",
    "\n",
    "**âš ï¸ Important:** The sample data contains intentional data quality issues that you must identify and resolve in your pipeline.\n",
    "\n",
    "You can now proceed to the requirements notebook to understand the exercise objectives."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6049106472219223,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_LDP_Exercise_Setup_Environment",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
