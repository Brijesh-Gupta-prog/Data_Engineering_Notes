{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c1e45b8-5bdf-4f66-9669-b4d03b402770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 6: Building RAG Applications with MLflow\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the complete RAG application workflow\n",
    "- Learn how to assemble RAG applications\n",
    "- Use MLflow for RAG solution management\n",
    "- Deploy and serve RAG applications\n",
    "- Manage RAG chains and pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95c0848f-9271-44b7-a595-7933e5788bbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. RAG Application Workflow Diagram\n",
    "\n",
    "### Complete RAG Application Flow\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              RAG Application Workflow                        │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────┐\n",
    "│  User Query  │\n",
    "└──────┬───────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Query Processing                                            │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  1. Embed query                                       │  │\n",
    "│  │  2. Search vector store                               │  │\n",
    "│  │  3. Retrieve top-k chunks                             │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Context Assembly                                            │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  - Combine retrieved chunks                           │  │\n",
    "│  │  - Apply filters                                      │  │\n",
    "│  │  - Re-rank if needed                                  │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Prompt Construction                                         │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  Context: [Retrieved chunks]                         │  │\n",
    "│  │  Question: [User query]                              │  │\n",
    "│  │  Instructions: [System prompts]                       │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Generation                                                  │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  LLM generates response                              │  │\n",
    "│  │  - Using augmented prompt                           │  │\n",
    "│  │  - With retrieved context                            │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌──────────────┐\n",
    "│   Response    │\n",
    "│  (with sources)│\n",
    "└──────────────┘\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Query Processing**: Convert query to embedding, search vector store\n",
    "2. **Context Assembly**: Retrieve and prepare relevant chunks\n",
    "3. **Prompt Construction**: Build augmented prompt\n",
    "4. **Generation**: LLM generates response\n",
    "5. **Response**: Return answer with source citations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7229d5da-3358-4f08-994f-a7ec6b4377d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Assembling a RAG Application\n",
    "\n",
    "### 2.1 Core Components\n",
    "\n",
    "A RAG application consists of:\n",
    "\n",
    "1. **Retrieval Component**:\n",
    "   - Vector search index\n",
    "   - Embedding model\n",
    "   - Retrieval logic\n",
    "\n",
    "2. **Augmentation Component**:\n",
    "   - Context assembly\n",
    "   - Prompt construction\n",
    "   - Filtering and ranking\n",
    "\n",
    "3. **Generation Component**:\n",
    "   - LLM model\n",
    "   - Prompt engineering\n",
    "   - Response formatting\n",
    "\n",
    "### 2.2 Building Blocks\n",
    "\n",
    "#### Retrieval Block\n",
    "\n",
    "```python\n",
    "def retrieve(query: str, top_k: int = 5):\n",
    "    # 1. Embed query\n",
    "    query_embedding = embedding_model(query)\n",
    "    \n",
    "    # 2. Search vector store\n",
    "    results = vector_search.query(\n",
    "        query_vector=query_embedding,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    \n",
    "    # 3. Return chunks\n",
    "    return results\n",
    "```\n",
    "\n",
    "#### Augmentation Block\n",
    "\n",
    "```python\n",
    "def augment_prompt(query: str, chunks: list):\n",
    "    # 1. Combine chunks\n",
    "    context = \"\\n\\n\".join([chunk.text for chunk in chunks])\n",
    "    \n",
    "    # 2. Construct prompt\n",
    "    prompt = f\"\"\"\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer based on the context above:\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "```\n",
    "\n",
    "#### Generation Block\n",
    "\n",
    "```python\n",
    "def generate(prompt: str):\n",
    "    # 1. Call LLM\n",
    "    response = llm.generate(prompt)\n",
    "    \n",
    "    # 2. Format response\n",
    "    return response\n",
    "```\n",
    "\n",
    "### 2.3 Complete RAG Chain\n",
    "\n",
    "```python\n",
    "class RAGChain:\n",
    "    def __init__(self, embedding_model, vector_search, llm):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.vector_search = vector_search\n",
    "        self.llm = llm\n",
    "    \n",
    "    def __call__(self, query: str):\n",
    "        # 1. Retrieve\n",
    "        chunks = self.retrieve(query)\n",
    "        \n",
    "        # 2. Augment\n",
    "        prompt = self.augment_prompt(query, chunks)\n",
    "        \n",
    "        # 3. Generate\n",
    "        response = self.generate(prompt)\n",
    "        \n",
    "        # 4. Return with sources\n",
    "        return {\n",
    "            \"answer\": response,\n",
    "            \"sources\": [chunk.metadata for chunk in chunks]\n",
    "        }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0c47113-bd20-4245-8c94-924ff7d006d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Using MLflow for RAG Solutions\n",
    "\n",
    "### 3.1 What is MLflow?\n",
    "\n",
    "**MLflow** is an open-source platform for managing the ML lifecycle, including:\n",
    "- **Tracking**: Log parameters, metrics, and artifacts\n",
    "- **Models**: Package and deploy models\n",
    "- **Registry**: Centralized model store\n",
    "- **Projects**: Reproducible ML workflows\n",
    "\n",
    "### 3.2 Why MLflow for RAG?\n",
    "\n",
    "**Benefits**:\n",
    "- **Version Control**: Track different RAG configurations\n",
    "- **Experimentation**: Compare different approaches\n",
    "- **Reproducibility**: Reproduce RAG setups\n",
    "- **Deployment**: Package and deploy RAG chains\n",
    "- **Monitoring**: Track performance over time\n",
    "\n",
    "### 3.3 MLflow Components for RAG\n",
    "\n",
    "#### Tracking RAG Experiments\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Start experiment\n",
    "mlflow.set_experiment(\"rag-experiments\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"chunk_size\", 500)\n",
    "    mlflow.log_param(\"top_k\", 5)\n",
    "    mlflow.log_param(\"embedding_model\", \"BGE-large\")\n",
    "    mlflow.log_param(\"llm\", \"gpt-4\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"retrieval_precision\", 0.85)\n",
    "    mlflow.log_metric(\"answer_accuracy\", 0.92)\n",
    "    mlflow.log_metric(\"latency_ms\", 250)\n",
    "    \n",
    "    # Log artifacts (prompts, examples)\n",
    "    mlflow.log_artifact(\"prompt_template.txt\")\n",
    "```\n",
    "\n",
    "#### Logging RAG Models\n",
    "\n",
    "```python\n",
    "# Log RAG chain as MLflow model\n",
    "mlflow.pyfunc.log_model(\n",
    "    \"rag_chain\",\n",
    "    python_model=RAGChain(...),\n",
    "    registered_model_name=\"rag-qa-system\"\n",
    ")\n",
    "```\n",
    "\n",
    "#### Model Registry\n",
    "\n",
    "```python\n",
    "# Register model\n",
    "mlflow.register_model(\n",
    "    \"runs:/<run_id>/rag_chain\",\n",
    "    \"rag-qa-system\"\n",
    ")\n",
    "\n",
    "# Transition to production\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"rag-qa-system\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "```\n",
    "\n",
    "### 3.4 RAG-Specific MLflow Features\n",
    "\n",
    "#### Custom RAG Metrics\n",
    "\n",
    "```python\n",
    "# Log custom RAG metrics\n",
    "mlflow.log_metric(\"context_precision\", 0.88)\n",
    "mlflow.log_metric(\"context_recall\", 0.82)\n",
    "mlflow.log_metric(\"faithfulness\", 0.91)\n",
    "mlflow.log_metric(\"answer_relevancy\", 0.89)\n",
    "```\n",
    "\n",
    "#### Prompt Versioning\n",
    "\n",
    "```python\n",
    "# Log prompt templates\n",
    "mlflow.log_text(prompt_template, \"prompt_template.txt\")\n",
    "\n",
    "# Track prompt changes\n",
    "mlflow.log_param(\"prompt_version\", \"v2.1\")\n",
    "```\n",
    "\n",
    "#### Retrieval Analysis\n",
    "\n",
    "```python\n",
    "# Log retrieval results\n",
    "mlflow.log_dict(retrieval_results, \"retrieval_results.json\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62520694-b193-481e-9ca5-4da52c88aa03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Deploying RAG Applications\n",
    "\n",
    "### 4.1 Model Serving\n",
    "\n",
    "**Deploy RAG chain as MLflow model**:\n",
    "\n",
    "```python\n",
    "# Deploy to Model Serving\n",
    "mlflow.deployments.create_deployment(\n",
    "    name=\"rag-qa-endpoint\",\n",
    "    model_uri=\"models:/rag-qa-system/Production\",\n",
    "    target_uri=\"databricks\"\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.2 Serving RAG Chains\n",
    "\n",
    "**Query deployed RAG endpoint**:\n",
    "\n",
    "```python\n",
    "# Query endpoint\n",
    "response = mlflow.deployments.predict(\n",
    "    deployment_name=\"rag-qa-endpoint\",\n",
    "    inputs={\"query\": \"What is RAG?\"}\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.3 Batch Processing\n",
    "\n",
    "**Process multiple queries**:\n",
    "\n",
    "```python\n",
    "# Batch processing\n",
    "queries = [\"What is RAG?\", \"How does vector search work?\"]\n",
    "results = mlflow.pyfunc.load_model(\"models:/rag-qa-system/Production\").predict(queries)\n",
    "```\n",
    "\n",
    "### 4.4 Real-time Serving\n",
    "\n",
    "**REST API endpoint**:\n",
    "\n",
    "```python\n",
    "# REST API\n",
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://<workspace>.databricks.com/serving-endpoints/rag-qa-endpoint/invocations\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "    json={\"query\": \"What is RAG?\"}\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "501591f5-2f68-4f6d-8092-1fc877ac5762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Managing RAG Chains\n",
    "\n",
    "### 5.1 Chain Configuration\n",
    "\n",
    "**Store configuration**:\n",
    "\n",
    "```python\n",
    "rag_config = {\n",
    "    \"retrieval\": {\n",
    "        \"top_k\": 5,\n",
    "        \"embedding_model\": \"BGE-large\",\n",
    "        \"similarity_threshold\": 0.7\n",
    "    },\n",
    "    \"augmentation\": {\n",
    "        \"max_context_length\": 2000,\n",
    "        \"include_metadata\": True\n",
    "    },\n",
    "    \"generation\": {\n",
    "        \"llm\": \"gpt-4\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "}\n",
    "\n",
    "mlflow.log_dict(rag_config, \"rag_config.json\")\n",
    "```\n",
    "\n",
    "### 5.2 Version Management\n",
    "\n",
    "**Track versions**:\n",
    "\n",
    "```python\n",
    "# Version different components\n",
    "mlflow.log_param(\"rag_chain_version\", \"v1.2.0\")\n",
    "mlflow.log_param(\"embedding_model_version\", \"BGE-large-v1.5\")\n",
    "mlflow.log_param(\"llm_version\", \"gpt-4-turbo\")\n",
    "```\n",
    "\n",
    "### 5.3 A/B Testing\n",
    "\n",
    "**Compare different configurations**:\n",
    "\n",
    "```python\n",
    "# Run A with configuration A\n",
    "with mlflow.start_run(run_name=\"config-a\"):\n",
    "    # ... RAG chain A\n",
    "    mlflow.log_metric(\"accuracy\", 0.92)\n",
    "\n",
    "# Run B with configuration B\n",
    "with mlflow.start_run(run_name=\"config-b\"):\n",
    "    # ... RAG chain B\n",
    "    mlflow.log_metric(\"accuracy\", 0.89)\n",
    "```\n",
    "\n",
    "### 5.4 Monitoring\n",
    "\n",
    "**Track performance**:\n",
    "\n",
    "```python\n",
    "# Log performance metrics\n",
    "mlflow.log_metric(\"avg_latency_ms\", 250)\n",
    "mlflow.log_metric(\"success_rate\", 0.98)\n",
    "mlflow.log_metric(\"error_rate\", 0.02)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "614206ed-bccf-4230-8306-78703ac807b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Best Practices\n",
    "\n",
    "### 6.1 Experimentation\n",
    "\n",
    "**Track everything**:\n",
    "- Parameters (chunk size, top_k, models)\n",
    "- Metrics (accuracy, latency, cost)\n",
    "- Artifacts (prompts, examples, results)\n",
    "\n",
    "### 6.2 Versioning\n",
    "\n",
    "**Version all components**:\n",
    "- RAG chain code\n",
    "- Prompt templates\n",
    "- Model versions\n",
    "- Configuration\n",
    "\n",
    "### 6.3 Testing\n",
    "\n",
    "**Test before deployment**:\n",
    "- Unit tests for each component\n",
    "- Integration tests for full chain\n",
    "- Performance tests\n",
    "- Quality tests\n",
    "\n",
    "### 6.4 Monitoring\n",
    "\n",
    "**Monitor in production**:\n",
    "- Latency\n",
    "- Error rates\n",
    "- Quality metrics\n",
    "- Cost\n",
    "\n",
    "## 7. Summary and Next Steps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **RAG applications** consist of retrieval, augmentation, and generation\n",
    "2. **MLflow** helps manage RAG lifecycle (experimentation, deployment, monitoring)\n",
    "3. **Version control** is crucial for RAG components\n",
    "4. **Deployment** options include real-time and batch processing\n",
    "5. **Monitoring** ensures production quality\n",
    "\n",
    "### Next Module: Evaluating RAG Applications\n",
    "\n",
    "In the next module, we'll explore:\n",
    "- Components to evaluate in RAG systems\n",
    "- Evaluation metrics (precision, recall, faithfulness, etc.)\n",
    "- MLflow evaluation for RAG\n",
    "- Best practices for RAG evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1bd455d-218a-44c2-a23c-cf63b5814383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Exercise 1**: Build a complete RAG chain with retrieval, augmentation, and generation\n",
    "2. **Exercise 2**: Use MLflow to track a RAG experiment with different configurations\n",
    "3. **Exercise 3**: Deploy a RAG chain as an MLflow model\n",
    "4. **Exercise 4**: Compare two RAG configurations using MLflow\n",
    "5. **Exercise 5**: Set up monitoring for a deployed RAG application\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "06_Building_RAG_Applications_with_MLflow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
