{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eef1eeec-e18d-45e7-b65b-7f52d96545c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 3: Data Preparation for RAG\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand why data preparation is critical for RAG success\n",
    "- Learn data extraction and chunking strategies\n",
    "- Explore embedding model selection\n",
    "- Handle complex and unstructured documents\n",
    "- Use Databricks tools for data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7a383d9-8f12-4f20-a6de-74628c233e92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Why is Data Prep Important for RAG?\n",
    "\n",
    "### The Foundation of RAG Quality\n",
    "\n",
    "**Data preparation is the foundation of RAG quality.** Poor data preparation leads to poor RAG performance, regardless of how sophisticated your retrieval or generation models are.\n",
    "\n",
    "### Potential Issues When Data is Prepared Improperly\n",
    "\n",
    "#### 1.1 Lost in the Middle\n",
    "\n",
    "**Problem**: Information in the middle of long contexts may be overlooked by LLMs.\n",
    "\n",
    "**Research**: \n",
    "- \"Lost in the Middle: How Language Models Use Long Contexts\" (Liu et al., 2023)\n",
    "- \"Needle in a Haystack\" test demonstrates this issue\n",
    "\n",
    "**Impact**: \n",
    "- Critical information may be missed\n",
    "- Retrieval returns relevant chunks, but model doesn't use them effectively\n",
    "\n",
    "**Solution**: \n",
    "- Proper chunking strategies\n",
    "- Re-ranking retrieved chunks\n",
    "- Limiting context length\n",
    "\n",
    "#### 1.2 Inefficient Retrieval\n",
    "\n",
    "**Problems**:\n",
    "- **Poor chunking**: Chunks too large/small, breaking semantic units\n",
    "- **Wrong embedding model**: Mismatch between query and document embeddings\n",
    "- **Missing metadata**: Can't filter or rank effectively\n",
    "\n",
    "**Impact**:\n",
    "- Low retrieval precision\n",
    "- Irrelevant chunks in context\n",
    "- Poor final responses\n",
    "\n",
    "#### 1.3 Exposing Data\n",
    "\n",
    "**Security Risks**:\n",
    "- Sensitive information in chunks\n",
    "- PII (Personally Identifiable Information) leakage\n",
    "- Confidential data exposure\n",
    "\n",
    "**Impact**:\n",
    "- Compliance violations\n",
    "- Security breaches\n",
    "- Privacy concerns\n",
    "\n",
    "**Solution**:\n",
    "- Data masking/redaction\n",
    "- Access controls\n",
    "- Chunk-level security\n",
    "\n",
    "#### 1.4 Wrong Embedding Model\n",
    "\n",
    "**Problems**:\n",
    "- Model doesn't match domain (e.g., using general model for code)\n",
    "- Model doesn't match language\n",
    "- Model doesn't capture semantic relationships needed\n",
    "\n",
    "**Impact**:\n",
    "- Poor semantic similarity\n",
    "- Mismatched query-document embeddings\n",
    "- Low retrieval quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df6a3b63-beb5-43a9-902f-946d0e9b480e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Data Prep Process Overview\n",
    "\n",
    "### Complete Data Preparation Pipeline\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              Data Preparation Pipeline                        │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "External Sources\n",
    "    │\n",
    "    ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Ingestion and Pre-processing                                │\n",
    "│  - Extract text from various formats                         │\n",
    "│  - Clean and normalize                                       │\n",
    "│  - Handle encoding issues                                     │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Data Storage and Governance                                 │\n",
    "│  - Delta Lake (storage)                                      │\n",
    "│  - Unity Catalog (governance)                                │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Chunking                                                    │\n",
    "│  - Split documents into chunks                               │\n",
    "│  - chunk1, chunk2, chunk3, ...                              │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Embedding                                                   │\n",
    "│  - Convert chunks to vectors                                 │\n",
    "│  - Using embedding models                                    │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Vector Store                                                │\n",
    "│  - Store embeddings and metadata                             │\n",
    "│  - Enable similarity search                                  │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Stages\n",
    "\n",
    "1. **Ingestion**: Bring data into the system\n",
    "2. **Storage**: Store in Delta Lake with Unity Catalog governance\n",
    "3. **Chunking**: Break into manageable pieces\n",
    "4. **Embedding**: Convert to vector representations\n",
    "5. **Indexing**: Store in vector database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07a692a5-2c7e-4024-8630-99074e06fd15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Data Storage and Governance\n",
    "\n",
    "### 3.1 What is Delta Lake?\n",
    "\n",
    "**Delta Lake** is an open-source storage layer that brings ACID transactions to data lakes:\n",
    "\n",
    "**Key Features**:\n",
    "- **ACID Transactions**: Ensures data consistency\n",
    "- **Time Travel**: Query historical versions of data\n",
    "- **Schema Enforcement**: Prevents bad data from entering\n",
    "- **Upserts and Deletes**: Efficient data updates\n",
    "- **Scalability**: Handles petabytes of data\n",
    "\n",
    "**Benefits for RAG**:\n",
    "- Reliable document storage\n",
    "- Version control for knowledge base\n",
    "- Efficient updates and deletions\n",
    "- Integration with Databricks ecosystem\n",
    "\n",
    "### 3.2 Unity Catalog\n",
    "\n",
    "**Unity Catalog** is Databricks' unified governance solution:\n",
    "\n",
    "**Features**:\n",
    "- **Centralized Metadata**: Single source of truth\n",
    "- **Fine-grained Access Control**: Table, column, row-level security\n",
    "- **Data Lineage**: Track data flow and transformations\n",
    "- **Audit Logging**: Compliance and security\n",
    "- **Cross-workspace Sharing**: Share data securely\n",
    "\n",
    "**Benefits for RAG**:\n",
    "- Secure access to documents\n",
    "- Compliance with data regulations\n",
    "- Track document sources and transformations\n",
    "- Manage permissions at chunk level\n",
    "\n",
    "### 3.3 Storage Architecture for RAG\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              RAG Data Storage Architecture                     │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                               │\n",
    "│  Unity Catalog                                                │\n",
    "│       │                                                       │\n",
    "│       ├─── Documents Table (Delta)                           │\n",
    "│       │    - document_id                                     │\n",
    "│       │    - source_path                                     │\n",
    "│       │    - content                                         │\n",
    "│       │    - metadata                                        │\n",
    "│       │                                                       │\n",
    "│       ├─── Chunks Table (Delta)                              │\n",
    "│       │    - chunk_id                                        │\n",
    "│       │    - document_id                                     │\n",
    "│       │    - chunk_text                                      │\n",
    "│       │    - chunk_index                                     │\n",
    "│       │    - metadata                                        │\n",
    "│       │                                                       │\n",
    "│       └─── Embeddings Table (Delta)                          │\n",
    "│            - chunk_id                                        │\n",
    "│            - embedding_vector                                │\n",
    "│            - model_name                                      │\n",
    "│                                                               │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09a1de3b-1226-40ac-ac75-8ed5c53a0616",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Data Extraction and Chunking\n",
    "\n",
    "### 4.1 Typical Process\n",
    "\n",
    "The standard RAG data preparation process:\n",
    "\n",
    "1. **Split document into chunks**\n",
    "   - Break large documents into smaller pieces\n",
    "   - Maintain semantic coherence\n",
    "\n",
    "2. **Embed the chunks with a model**\n",
    "   - Convert text to vector representations\n",
    "   - Capture semantic meaning\n",
    "\n",
    "3. **Store in a vector store**\n",
    "   - Index for fast retrieval\n",
    "   - Store with metadata\n",
    "\n",
    "### 4.2 Constraints and Risks\n",
    "\n",
    "#### Risk: Chunk Could Be Out of Context\n",
    "\n",
    "**Problem**: Breaking documents arbitrarily can lose context\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Original: \"The company's revenue increased by 25% in Q3. This growth \n",
    "was driven by strong performance in the European market.\"\n",
    "\n",
    "Bad Chunk 1: \"The company's revenue increased by 25% in Q3.\"\n",
    "Bad Chunk 2: \"This growth was driven by strong performance in the \n",
    "European market.\"\n",
    "\n",
    "Issue: Chunk 1 lacks context about what caused the growth.\n",
    "```\n",
    "\n",
    "**Solution**: Use semantic chunking or maintain context windows\n",
    "\n",
    "### 4.3 How to Chunk Data?\n",
    "\n",
    "#### Strategy 1: Semantic Chunking\n",
    "\n",
    "**Approach**: Split based on semantic boundaries (sentences, paragraphs, sections)\n",
    "\n",
    "**Advantages**:\n",
    "- Preserves semantic meaning\n",
    "- Natural boundaries\n",
    "- Better for retrieval\n",
    "\n",
    "**Implementation**:\n",
    "- Use sentence transformers to find semantic boundaries\n",
    "- Split at paragraph breaks\n",
    "- Respect document structure (headers, sections)\n",
    "\n",
    "#### Strategy 2: Fixed Size Chunking\n",
    "\n",
    "**Approach**: Split into fixed-size chunks (e.g., 500 tokens, 1000 characters)\n",
    "\n",
    "**Advantages**:\n",
    "- Simple to implement\n",
    "- Predictable chunk sizes\n",
    "- Easy to manage\n",
    "\n",
    "**Disadvantages**:\n",
    "- May break semantic units\n",
    "- Can lose context\n",
    "\n",
    "**Implementation**:\n",
    "```python\n",
    "# Example: Fixed size chunking\n",
    "def chunk_fixed_size(text, chunk_size=500, overlap=50):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a498564c-2601-4798-a209-b9dee57cd896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.4 Chunking Strategy is Use-Case Specific\n",
    "\n",
    "**Key Principle**: There is no one-size-fits-all chunking strategy. It depends on:\n",
    "- Document type\n",
    "- Query patterns\n",
    "- Use case requirements\n",
    "- Model capabilities\n",
    "\n",
    "#### Consider Your Document Length\n",
    "\n",
    "**Questions to Ask**:\n",
    "- How long are your documents?\n",
    "- Are they single sentences, paragraphs, or multi-page documents?\n",
    "- What's the typical query length?\n",
    "\n",
    "#### Chunk Size Trade-offs\n",
    "\n",
    "**1 Chunk = 1 Sentence**\n",
    "- **Pros**: \n",
    "  - Very specific embeddings\n",
    "  - Precise retrieval\n",
    "- **Cons**: \n",
    "  - Embedding may lack broader context\n",
    "  - May miss relationships between sentences\n",
    "\n",
    "**1 Chunk = Multiple Paragraphs**\n",
    "- **Pros**: \n",
    "  - Embeddings capture broader themes\n",
    "  - Better for longer queries\n",
    "- **Cons**: \n",
    "  - Less precise retrieval\n",
    "  - May include irrelevant information\n",
    "\n",
    "**Splitting by Headers**\n",
    "- **Pros**: \n",
    "  - Respects document structure\n",
    "  - Natural semantic boundaries\n",
    "- **Cons**: \n",
    "  - Header sizes vary\n",
    "  - May need additional splitting\n",
    "\n",
    "#### Chunk Overlap\n",
    "\n",
    "**Chunk Overlap** defines the amount of overlap between consecutive chunks, ensuring that no contextual information is lost between them.\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Document: \"A B C D E F G H I J\"\n",
    "Chunk size: 5\n",
    "Overlap: 2\n",
    "\n",
    "Chunk 1: \"A B C D E\"\n",
    "Chunk 2: \"D E F G H\"  (overlaps with chunk 1)\n",
    "Chunk 3: \"G H I J\"    (overlaps with chunk 2)\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Preserves context at boundaries\n",
    "- Reduces information loss\n",
    "- Improves retrieval for boundary queries\n",
    "\n",
    "**Trade-off**: More overlap = more chunks = higher storage cost\n",
    "\n",
    "#### Windowed Summarization\n",
    "\n",
    "**Windowed Summarization** is a context-enriching chunking method where each chunk includes a windowed summary of previous few chunks.\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Chunk 1: [Original content]\n",
    "Chunk 2: [Summary of Chunk 1] + [Original content]\n",
    "Chunk 3: [Summary of Chunks 1-2] + [Original content]\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Maintains context across chunks\n",
    "- Better for long documents\n",
    "- Improves retrieval quality\n",
    "\n",
    "#### Query Pattern Considerations\n",
    "\n",
    "**Prior knowledge of user's query patterns can be helpful:**\n",
    "\n",
    "- **Longer queries**: May have better aligned embeddings to returned chunks\n",
    "- **Shorter queries**: Could be more precise but may miss broader context\n",
    "\n",
    "**Strategy**: \n",
    "- Analyze query patterns\n",
    "- Adjust chunk size accordingly\n",
    "- Consider hybrid approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0feaa5e-7b34-4e34-b68c-d02e38a95122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.5 Advanced Chunking Strategies\n",
    "\n",
    "#### Summarization-Based Chunking\n",
    "\n",
    "**Approach**: Create chunks with summaries of previous context\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Original Document:\n",
    "Section 1: Introduction to RAG\n",
    "Section 2: Data Preparation\n",
    "Section 3: Vector Stores\n",
    "\n",
    "Chunk 1: \n",
    "[Section 1 content]\n",
    "\n",
    "Chunk 2:\n",
    "Summary: \"The document introduces RAG (Retrieval-Augmented Generation) \n",
    "as a pattern for enhancing LLMs with external knowledge.\"\n",
    "[Section 2 content]\n",
    "\n",
    "Chunk 3:\n",
    "Summary: \"RAG requires careful data preparation including chunking and \n",
    "embedding. Vector stores enable efficient similarity search.\"\n",
    "[Section 3 content]\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Maintains context across sections\n",
    "- Better for hierarchical documents\n",
    "- Improves retrieval for broad queries\n",
    "\n",
    "#### Summarization with Metadata\n",
    "\n",
    "**Approach**: Include structured metadata with each chunk\n",
    "\n",
    "**Example**:\n",
    "```json\n",
    "{\n",
    "  \"chunk_id\": \"chunk_001\",\n",
    "  \"document_id\": \"doc_123\",\n",
    "  \"content\": \"[chunk text]\",\n",
    "  \"metadata\": {\n",
    "    \"section\": \"Introduction\",\n",
    "    \"subsection\": \"What is RAG?\",\n",
    "    \"page_number\": 1,\n",
    "    \"summary\": \"This section introduces RAG...\",\n",
    "    \"keywords\": [\"RAG\", \"retrieval\", \"augmentation\"],\n",
    "    \"previous_context\": \"Summary of previous sections...\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Rich filtering capabilities\n",
    "- Better ranking\n",
    "- Improved retrieval precision\n",
    "- Easier debugging\n",
    "\n",
    "**Use Cases**:\n",
    "- Technical documentation\n",
    "- Research papers\n",
    "- Legal documents\n",
    "- Multi-section reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3e2d292-88b1-4e0a-ba27-76db93c1e3a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Data Extraction and Chunking Challenges\n",
    "\n",
    "### 5.1 Working with Complex Documents\n",
    "\n",
    "Real-world documents often contain:\n",
    "\n",
    "- **Mixed content**: Text, images, tables, prices, disclaimers\n",
    "- **Irregular layouts**: Text mixed with images, irregular text placement\n",
    "- **Color encoding**: Important information highlighted by color\n",
    "- **Hierarchical information**: Charts with nested data\n",
    "- **Multi-column layouts**: Order of columns is crucial\n",
    "- **Images with context**: Images must stay with related text\n",
    "\n",
    "### 5.2 Specific Challenges\n",
    "\n",
    "#### Challenge 1: Preserving Information Order\n",
    "\n",
    "**Problem**: Keeping the order of information is critical\n",
    "\n",
    "**Example - Multi-column Text**:\n",
    "```\n",
    "Column 1          Column 2\n",
    "Item A            Price: $10\n",
    "Item B            Price: $20\n",
    "```\n",
    "\n",
    "If order is lost: \"Price: $10\" might be associated with \"Item B\"\n",
    "\n",
    "**Solution**: \n",
    "- Use layout-aware extraction\n",
    "- Preserve spatial relationships\n",
    "- Maintain reading order\n",
    "\n",
    "#### Challenge 2: Keeping Images with Related Information\n",
    "\n",
    "**Problem**: Images provide crucial context that must be preserved\n",
    "\n",
    "**Example**: \n",
    "- Product image with description\n",
    "- Chart with explanation text\n",
    "- Diagram with annotations\n",
    "\n",
    "**Solution**:\n",
    "- Extract image-text relationships\n",
    "- Store images with metadata\n",
    "- Use multimodal models\n",
    "\n",
    "#### Challenge 3: Preserving Logical Sections\n",
    "\n",
    "**Problem**: Some document types require structure preservation\n",
    "\n",
    "**Example - HTML Documents**:\n",
    "- HTML requires tag-based chunking to preserve logical structure\n",
    "- Tables, lists, sections need special handling\n",
    "\n",
    "**Challenge - HTML Tables**:\n",
    "- HTML tables are token-heavy\n",
    "- Example: 3x3 small table\n",
    "  - Plain text: 11 tokens\n",
    "  - JSON: 29 tokens  \n",
    "  - HTML: 132 tokens\n",
    "\n",
    "**Solution**: \n",
    "- Convert HTML to structured format\n",
    "- Extract tables separately\n",
    "- Use specialized parsers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "095530f9-03be-45e5-91a5-09850d9fc135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5.3 General Approaches to Address Unstructured/Complex Documents\n",
    "\n",
    "#### Approach 1: Traditional Libraries\n",
    "\n",
    "**Libraries**: PyMuPDF, pdfplumber, python-docx\n",
    "\n",
    "**Features**:\n",
    "- Text extraction from PDFs, Word docs\n",
    "- Basic layout detection\n",
    "- Table extraction\n",
    "- Metadata extraction\n",
    "\n",
    "**Limitations**:\n",
    "- May not preserve complex layouts\n",
    "- Limited understanding of document structure\n",
    "- Manual post-processing often needed\n",
    "\n",
    "**Example - PyMuPDF**:\n",
    "```python\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "doc = fitz.open(\"document.pdf\")\n",
    "for page in doc:\n",
    "    text = page.get_text()\n",
    "    # Process text...\n",
    "```\n",
    "\n",
    "#### Approach 2: Layout Models\n",
    "\n",
    "**Libraries**: \n",
    "- Hugging Face's LayoutLMv3\n",
    "- DocTR (Document Text Recognition)\n",
    "- Unstructured.io\n",
    "- PyPDF2\n",
    "\n",
    "**Features**:\n",
    "- Apply deep learning models for text extraction\n",
    "- Context extraction from layout\n",
    "- Better handling of complex documents\n",
    "- Understanding of document structure\n",
    "\n",
    "**Advantages**:\n",
    "- Better accuracy for complex layouts\n",
    "- Preserves relationships between elements\n",
    "- Handles tables, forms, multi-column layouts\n",
    "\n",
    "**Example - Unstructured**:\n",
    "```python\n",
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(filename=\"document.pdf\")\n",
    "# Returns structured elements with layout information\n",
    "```\n",
    "\n",
    "#### Approach 3: Multimodal Models\n",
    "\n",
    "**Models**:\n",
    "- OpenAI GPT-4o (and beyond)\n",
    "- Alphabet's Gemini 1.5 and beyond\n",
    "- Open-source: Dolphin series, OpenFlamingo, LLaVA, OLMo\n",
    "\n",
    "**Features**:\n",
    "- Multimodal LLMs intrinsically understand images\n",
    "- Can process text and images together\n",
    "- Better context understanding\n",
    "\n",
    "**Current Status**:\n",
    "- More experimental at this stage\n",
    "- Rapidly improving\n",
    "- Best for documents with rich visual content\n",
    "\n",
    "**Use Cases**:\n",
    "- Documents with charts and graphs\n",
    "- Screenshots with text\n",
    "- Mixed media content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e703120-11c8-4204-8dd1-41a83d05cedc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Embedding Models\n",
    "\n",
    "### 6.1 What is an Embedding?\n",
    "\n",
    "**Embedding** is a numerical representation of text (or other data) in a high-dimensional vector space where semantically similar items are close together.\n",
    "\n",
    "**Visualization**: \n",
    "```\n",
    "Text: \"machine learning\"\n",
    "Embedding: [0.23, -0.45, 0.67, ..., 0.12]  (vector of numbers)\n",
    "\n",
    "Similar texts have similar vectors:\n",
    "\"machine learning\" ≈ \"ML\" ≈ \"artificial intelligence\"\n",
    "```\n",
    "\n",
    "### 6.2 Dimensionality Reduction for Visualization\n",
    "\n",
    "**Concept**: High-dimensional embeddings (e.g., 768, 1536 dimensions) can be reduced to 2D/3D for visualization using techniques like:\n",
    "- t-SNE\n",
    "- UMAP\n",
    "- PCA\n",
    "\n",
    "**Purpose**: \n",
    "- Understand embedding space\n",
    "- Visualize semantic relationships\n",
    "- Debug embedding quality\n",
    "\n",
    "**Example Visualization**:\n",
    "```\n",
    "2D Projection:\n",
    "    [ML] ---- [AI]\n",
    "      |         |\n",
    "      |         |\n",
    "   [Deep] --- [Neural]\n",
    "```\n",
    "\n",
    "### 6.3 Choosing the Right Model for Your Application\n",
    "\n",
    "#### Factor 1: Data Text Properties\n",
    "\n",
    "**Consider**:\n",
    "- **Language**: Is your data in English, multilingual, or specific languages?\n",
    "- **Domain**: General, technical, medical, legal, code?\n",
    "- **Text Type**: Short queries, long documents, code snippets?\n",
    "\n",
    "**Examples**:\n",
    "- **Multilingual**: Use multilingual models (e.g., multilingual-MiniLM)\n",
    "- **Code**: Use code-specific models (e.g., CodeBERT)\n",
    "- **Medical**: Use domain-specific models (e.g., BioBERT)\n",
    "\n",
    "#### Factor 2: Model Capabilities\n",
    "\n",
    "**Consider**:\n",
    "- **Embedding Dimension**: Higher dimensions = more capacity but more storage\n",
    "- **Max Sequence Length**: How long can input be?\n",
    "- **Training Data**: What was the model trained on?\n",
    "\n",
    "**Common Dimensions**:\n",
    "- 384: Smaller, faster (e.g., all-MiniLM-L6-v2)\n",
    "- 768: Balanced (e.g., BERT-base)\n",
    "- 1536: Larger, more capacity (e.g., OpenAI ada-002)\n",
    "\n",
    "#### Factor 3: Practical Considerations\n",
    "\n",
    "**Window Limits**:\n",
    "- Model's maximum input length\n",
    "- Your document/chunk sizes\n",
    "- Query lengths\n",
    "\n",
    "**Benchmarking**:\n",
    "- Test on your specific data\n",
    "- Measure retrieval quality\n",
    "- Compare multiple models\n",
    "\n",
    "### 6.4 Embedding Model Requirements\n",
    "\n",
    "#### Requirement 1: Represent Both Queries and Documents\n",
    "\n",
    "**Critical**: The embedding model must work well for both:\n",
    "- **Query embeddings**: Short, question-like text\n",
    "- **Document embeddings**: Longer, document-like text\n",
    "\n",
    "**Problem**: Some models are optimized for one or the other\n",
    "\n",
    "**Solution**: Use models trained for both (e.g., BGE, OpenAI ada-002)\n",
    "\n",
    "#### Requirement 2: Ensure Similar Embedding Space\n",
    "\n",
    "**Critical**: Query and document embeddings must be in the same embedding space\n",
    "\n",
    "**Problem**: Using different models for queries and documents creates mismatched spaces\n",
    "\n",
    "**Solution**: \n",
    "- Use the same model for both\n",
    "- Use models trained together (e.g., query-document pairs)\n",
    "- Fine-tune on your data if needed\n",
    "\n",
    "**Example - What NOT to do**:\n",
    "```python\n",
    "# WRONG: Different models\n",
    "query_embedding = model_A(query)      # Model A\n",
    "doc_embedding = model_B(document)     # Model B\n",
    "# These won't be comparable!\n",
    "```\n",
    "\n",
    "**Example - What to do**:\n",
    "```python\n",
    "# CORRECT: Same model\n",
    "query_embedding = model(query)         # Same model\n",
    "doc_embedding = model(document)       # Same model\n",
    "# These are in the same space!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "097b0b5a-db59-403a-b00b-325eee686757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Unstructured Data Prep in Databricks\n",
    "\n",
    "### Complete Pipeline\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│        Unstructured Data Prep in Databricks                  │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────┐\n",
    "│  Ingestion   │\n",
    "│  (Tables &   │  → Load documents from various sources\n",
    "│   Volumes)   │\n",
    "└──────┬───────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Document Processing                                         │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  Workflow / DLT / Notebooks                          │  │\n",
    "│  │  - Extract text from PDFs, DOCX, etc.                │  │\n",
    "│  │  - Chunk documents                                    │  │\n",
    "│  │  - Extract metadata                                   │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Chunks and Features                                        │\n",
    "│  - Chunk text                                               │\n",
    "│  - Metadata                                                 │\n",
    "│  - Document relationships                                   │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Storage (Delta Tables)                                     │\n",
    "│  - Store chunks                                             │\n",
    "│  - Store metadata                                           │\n",
    "│  - Unity Catalog governance                                 │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Automatic Sync                                              │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  Vector DB (Vector Search)                           │  │\n",
    "│  │  - Databricks computes embeddings automatically     │  │\n",
    "│  │  - Syncs with Delta tables                           │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Model Serving                                               │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  - Custom models                                       │  │\n",
    "│  │  - External models (OpenAI ada-002)                   │  │\n",
    "│  │  - Foundational models (BGE)                          │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Databricks Features\n",
    "\n",
    "1. **Ingestion**: \n",
    "   - Tables: Structured data storage\n",
    "   - Volumes: Unstructured file storage\n",
    "\n",
    "2. **Processing**:\n",
    "   - Workflows: Orchestrate processing pipelines\n",
    "   - DLT (Delta Live Tables): Declarative data pipelines\n",
    "   - Notebooks: Custom processing logic\n",
    "\n",
    "3. **Storage**:\n",
    "   - Delta Tables: ACID transactions, versioning\n",
    "   - Unity Catalog: Governance and security\n",
    "\n",
    "4. **Vector Search**:\n",
    "   - Automatic embedding computation\n",
    "   - Delta table sync\n",
    "   - Managed vector database\n",
    "\n",
    "5. **Model Serving**:\n",
    "   - Host embedding models\n",
    "   - Support for various model types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc4053a3-cb6a-456a-8f28-4a40ace26619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. Structured Data Prep in Databricks\n",
    "\n",
    "### Structured vs Unstructured Data\n",
    "\n",
    "**Structured Data**:\n",
    "- Tables, databases\n",
    "- CSV, Parquet, Delta tables\n",
    "- Already in organized format\n",
    "\n",
    "**Unstructured Data**:\n",
    "- Documents, PDFs, images\n",
    "- Free-form text\n",
    "- Requires extraction\n",
    "\n",
    "### Structured Data Preparation\n",
    "\n",
    "**Process**:\n",
    "1. **Data Cleaning**:\n",
    "   - Handle missing values\n",
    "   - Normalize formats\n",
    "   - Remove duplicates\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Create embeddings from structured fields\n",
    "   - Combine multiple columns\n",
    "   - Extract metadata\n",
    "\n",
    "3. **Storage**:\n",
    "   - Delta tables\n",
    "   - Unity Catalog\n",
    "\n",
    "4. **Embedding**:\n",
    "   - Convert structured data to text\n",
    "   - Generate embeddings\n",
    "   - Store in vector search\n",
    "\n",
    "**Example - Product Catalog**:\n",
    "```python\n",
    "# Structured data\n",
    "products = {\n",
    "    \"product_id\": \"123\",\n",
    "    \"name\": \"Laptop\",\n",
    "    \"description\": \"High-performance laptop\",\n",
    "    \"category\": \"Electronics\",\n",
    "    \"price\": 999.99\n",
    "}\n",
    "\n",
    "# Convert to text for embedding\n",
    "text = f\"{products['name']} {products['description']} {products['category']}\"\n",
    "embedding = embedding_model(text)\n",
    "```\n",
    "\n",
    "### Hybrid Approaches\n",
    "\n",
    "**Combine structured and unstructured**:\n",
    "- Use structured metadata for filtering\n",
    "- Use unstructured content for semantic search\n",
    "- Best of both worlds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34bd0fb2-2cc2-4a04-ab52-b411ae01b9fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Data preparation is critical** - quality of RAG depends on data prep\n",
    "2. **Chunking strategy matters** - use-case specific, requires experimentation\n",
    "3. **Embedding model selection** - must match domain, language, and use case\n",
    "4. **Complex documents** - require specialized tools and approaches\n",
    "5. **Databricks provides** - integrated tools for the entire pipeline\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "1. ❌ Using wrong chunk sizes (too large/small)\n",
    "2. ❌ Not preserving context between chunks\n",
    "3. ❌ Mismatched embedding models for queries and documents\n",
    "4. ❌ Ignoring document structure\n",
    "5. ❌ Not testing on your specific data\n",
    "\n",
    "### Next Module: Vector Stores and Search\n",
    "\n",
    "In the next module, we'll explore:\n",
    "- What vector databases are and why they're important\n",
    "- Vector similarity and distance metrics\n",
    "- Vector search strategies\n",
    "- How to filter and rank results\n",
    "- Introduction to Databricks Vector Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8240463-8111-463f-a80c-ed4e5b1756f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Exercise 1**: Design a chunking strategy for a specific document type (e.g., research papers, product catalogs)\n",
    "2. **Exercise 2**: Compare fixed-size vs semantic chunking on a sample document\n",
    "3. **Exercise 3**: Select an appropriate embedding model for a given use case\n",
    "4. **Exercise 4**: Design a data preparation pipeline for complex PDFs with tables and images\n",
    "5. **Exercise 5**: Create a chunking strategy with metadata for a multi-section document\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "03_Data_Preparation_for_RAG",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
