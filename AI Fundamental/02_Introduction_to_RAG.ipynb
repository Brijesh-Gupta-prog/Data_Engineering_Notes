{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1009b907-63eb-4610-bd4a-f3c409bde060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 2: Introduction to Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand how language models learn knowledge\n",
    "- Learn what RAG is and why it's needed\n",
    "- Explore RAG architecture and workflow\n",
    "- Understand RAG use cases and benefits\n",
    "- Map RAG concepts to Databricks features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2996188e-a5b2-4005-9dad-94b412b67ce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. How Do Language Models Learn Knowledge?\n",
    "\n",
    "Language models acquire knowledge through several mechanisms:\n",
    "\n",
    "### 1.1 Model Pre-training\n",
    "\n",
    "**Pre-training** is the initial phase where models learn from vast amounts of text data:\n",
    "\n",
    "- **Process**: Models are trained on billions of tokens from diverse sources (books, websites, articles, etc.)\n",
    "- **Knowledge Acquisition**: Models learn patterns, facts, relationships, and language structure\n",
    "- **Limitation**: Knowledge is \"frozen\" at training time - models don't know about events after their training cutoff date\n",
    "\n",
    "**Example**: A model trained in 2023 won't know about events in 2024.\n",
    "\n",
    "### 1.2 Model Fine-tuning\n",
    "\n",
    "**Fine-tuning** adapts pre-trained models for specific tasks or domains:\n",
    "\n",
    "- **Process**: Further training on domain-specific or task-specific datasets\n",
    "- **Use Cases**: \n",
    "  - Domain adaptation (medical, legal, financial)\n",
    "  - Task specialization (summarization, translation, classification)\n",
    "- **Limitation**: Still constrained by training data and cutoff date\n",
    "\n",
    "### 1.3 Passing Contextual Information (RAG Focus)\n",
    "\n",
    "**Context passing** provides real-time, external information to models:\n",
    "\n",
    "- **Process**: Retrieve relevant information and include it in the prompt\n",
    "- **Advantage**: Access to up-to-date, domain-specific, or proprietary information\n",
    "- **This is the core of RAG** - the focus of this course!\n",
    "\n",
    "**Comparison:**\n",
    "\n",
    "| Method | Knowledge Source | Up-to-date? | Domain-specific? | Cost |\n",
    "|--------|-----------------|-------------|------------------|------|\n",
    "| Pre-training | Training data | No | Limited | High (one-time) |\n",
    "| Fine-tuning | Training data | No | Yes (with effort) | High |\n",
    "| Context Passing (RAG) | External sources | Yes | Yes | Low (per query) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f915a4c4-9800-4804-ae9b-cbfa3b6a1136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Passing Context to LMs Helps Factual Recall\n",
    "\n",
    "### Why Context Matters\n",
    "\n",
    "Research shows that providing relevant context significantly improves:\n",
    "- **Factual accuracy**: Models can reference specific information\n",
    "- **Relevance**: Responses are grounded in provided context\n",
    "- **Reduction of hallucinations**: Less likely to make up information\n",
    "\n",
    "### Passing Context as Input\n",
    "\n",
    "**Approach**: Include relevant documents, data, or information directly in the prompt\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Context: \n",
    "[Relevant document 1]\n",
    "[Relevant document 2]\n",
    "\n",
    "Question: Based on the context above, what is the main finding?\n",
    "```\n",
    "\n",
    "### Downsides of Long Context\n",
    "\n",
    "1. **Token Limits**: Models have maximum context windows (e.g., 8K, 32K, 128K tokens)\n",
    "2. **Cost**: More tokens = higher API costs\n",
    "3. **Performance**: Processing long contexts can be slower\n",
    "4. **Relevance**: Not all context is equally relevant - noise can degrade quality\n",
    "5. **Lost in the Middle**: Models may struggle with information in the middle of long contexts\n",
    "\n",
    "### Evolution: Larger Context Windows\n",
    "\n",
    "**LLMs are evolving to accept larger/infinite contexts:**\n",
    "- **GPT-4 Turbo**: 128K tokens\n",
    "- **Claude 3**: 200K tokens\n",
    "- **Gemini 1.5**: Up to 1M tokens\n",
    "- **Research**: Infinite context models (e.g., Infini-attention)\n",
    "\n",
    "**However**, even with large contexts:\n",
    "- Retrieval is still more efficient than including everything\n",
    "- Relevance filtering is crucial\n",
    "- Cost considerations remain important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "422027a5-b69e-483b-8eb9-4345d620c1e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. What is RAG?\n",
    "\n",
    "### Definition\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** is a pattern that combines:\n",
    "- **Retrieval**: Finding relevant information from external knowledge sources\n",
    "- **Augmentation**: Adding retrieved context to prompts\n",
    "- **Generation**: Using language models to generate responses based on augmented prompts\n",
    "\n",
    "### RAG as a Pattern\n",
    "\n",
    "RAG is not a specific technology or tool - it's an **architectural pattern** that can be implemented using various technologies.\n",
    "\n",
    "### How RAG Works\n",
    "\n",
    "1. **User Query**: User asks a question\n",
    "2. **Retrieval**: System searches knowledge base for relevant information\n",
    "3. **Augmentation**: Retrieved information is added to the prompt\n",
    "4. **Generation**: LLM generates response using the augmented prompt\n",
    "5. **Response**: User receives an answer grounded in retrieved context\n",
    "\n",
    "### The Main Problem RAG Solves: The Knowledge Gap\n",
    "\n",
    "**The Knowledge Gap Problem:**\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Knowledge Gap                             │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                              │\n",
    "│  ┌──────────────┐         ┌──────────────┐                 │\n",
    "│  │   LLM        │         │  External    │                 │\n",
    "│  │  Knowledge   │   ≠     │  Knowledge   │                 │\n",
    "│  │  (Training)  │         │  (Real-time) │                 │\n",
    "│  └──────────────┘         └──────────────┘                 │\n",
    "│                                                              │\n",
    "│  • Outdated information     • Up-to-date data              │\n",
    "│  • General knowledge        • Domain-specific info         │\n",
    "│  • Public data              • Proprietary documents         │\n",
    "│  • Static                   • Dynamic                      │\n",
    "│                                                              │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**RAG bridges this gap by:**\n",
    "- Retrieving relevant external knowledge\n",
    "- Augmenting prompts with this knowledge\n",
    "- Enabling accurate, up-to-date responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3655f77-22fe-47a7-a52c-c74061bb6ec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. RAG Use Cases\n",
    "\n",
    "### 4.1 Question-Answering Chatbots\n",
    "\n",
    "**Use Case**: Customer support, internal knowledge bases, documentation assistants\n",
    "\n",
    "**Example**: \n",
    "- User: \"How do I reset my password?\"\n",
    "- System retrieves relevant documentation\n",
    "- LLM generates answer based on retrieved docs\n",
    "\n",
    "**Benefits**:\n",
    "- Accurate, up-to-date answers\n",
    "- Reduced support burden\n",
    "- 24/7 availability\n",
    "\n",
    "### 4.2 Search Augmentation\n",
    "\n",
    "**Use Case**: Enhanced search experiences with natural language understanding\n",
    "\n",
    "**Example**:\n",
    "- Traditional search: Keyword matching\n",
    "- RAG-enhanced search: Semantic understanding + keyword matching\n",
    "\n",
    "**Benefits**:\n",
    "- Better relevance\n",
    "- Natural language queries\n",
    "- Contextual results\n",
    "\n",
    "### 4.3 Content Creation and Summarization\n",
    "\n",
    "**Use Case**: Generate content or summaries based on specific documents\n",
    "\n",
    "**Example**:\n",
    "- Input: Multiple research papers\n",
    "- Output: Comprehensive summary with citations\n",
    "\n",
    "**Benefits**:\n",
    "- Grounded in source material\n",
    "- Citable references\n",
    "- Domain-specific content\n",
    "\n",
    "### 4.4 Other Use Cases\n",
    "\n",
    "- **Legal Document Analysis**: Query contracts, regulations, case law\n",
    "- **Medical Information Systems**: Access medical literature, guidelines\n",
    "- **Financial Analysis**: Query financial reports, market data\n",
    "- **Technical Documentation**: Code documentation, API references\n",
    "- **Personalized Recommendations**: Based on user history and preferences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b906023-a673-4f8b-88a2-7bc9f57fab4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Main Concepts of RAG Workflow\n",
    "\n",
    "### 5.1 Index and Embed\n",
    "\n",
    "**Indexing**: Process of preparing documents for retrieval\n",
    "- **Chunking**: Breaking documents into manageable pieces\n",
    "- **Embedding**: Converting text chunks into vector representations\n",
    "- **Storage**: Storing embeddings in a vector database\n",
    "\n",
    "**Key Concept**: Documents are converted to embeddings (vectors) that capture semantic meaning.\n",
    "\n",
    "### 5.2 Vector Store\n",
    "\n",
    "**Vector Store**: Database optimized for storing and querying vector embeddings\n",
    "\n",
    "**Features**:\n",
    "- Efficient similarity search\n",
    "- Metadata storage\n",
    "- Scalability\n",
    "- Fast retrieval\n",
    "\n",
    "**Examples**: Pinecone, Weaviate, Milvus, Databricks Vector Search\n",
    "\n",
    "### 5.3 Retrieval\n",
    "\n",
    "**Retrieval**: Finding relevant documents/chunks based on query\n",
    "\n",
    "**Process**:\n",
    "1. Convert query to embedding\n",
    "2. Search vector store for similar embeddings\n",
    "3. Return top-k most similar chunks\n",
    "\n",
    "**Metrics**: Cosine similarity, Euclidean distance, dot product\n",
    "\n",
    "### 5.4 Filtering and Ranking\n",
    "\n",
    "**Filtering**: Narrowing results based on metadata\n",
    "- Date ranges\n",
    "- Document types\n",
    "- Categories\n",
    "- Access controls\n",
    "\n",
    "**Ranking**: Ordering results by relevance\n",
    "- Similarity scores\n",
    "- Re-ranking models\n",
    "- Hybrid approaches (keyword + semantic)\n",
    "\n",
    "### 5.5 Prompt Augmentation\n",
    "\n",
    "**Augmentation**: Adding retrieved context to the prompt\n",
    "\n",
    "**Structure**:\n",
    "```\n",
    "Context:\n",
    "[Retrieved document 1]\n",
    "[Retrieved document 2]\n",
    "...\n",
    "\n",
    "Question: [User's question]\n",
    "\n",
    "Answer:\n",
    "```\n",
    "\n",
    "### 5.6 Generation\n",
    "\n",
    "**Generation**: LLM produces response based on augmented prompt\n",
    "\n",
    "**Considerations**:\n",
    "- Model selection\n",
    "- Temperature settings\n",
    "- Max tokens\n",
    "- Response format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bdf0c46-0d8e-4eca-ba5e-9e6861692b6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. RAG Sample Architecture Diagram\n",
    "\n",
    "### Complete RAG Flow\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    RAG Architecture                              │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────┐\n",
    "│   Source     │\n",
    "│  Documents   │  (PDFs, Docs, Web pages, etc.)\n",
    "│  (PDF, DOCX) │\n",
    "└──────┬───────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Document Processing                                         │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  Chunking: Split documents into chunks              │  │\n",
    "│  │  Embedding: Convert chunks to vectors               │  │\n",
    "│  │  (Using Mosaic AI Model Serving - Embeddings)       │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Vector Store                                               │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  Mosaic AI Vector Search                              │  │\n",
    "│  │  - Stores embeddings                                  │  │\n",
    "│  │  - Enables similarity search                         │  │\n",
    "│  │  - Manages metadata                                  │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────┐\n",
    "│  User Query  │  \"What is the refund policy?\"\n",
    "└──────┬───────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Query Processing                                           │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  1. Convert query to embedding                       │  │\n",
    "│  │     (Using Mosaic AI Model Serving)                  │  │\n",
    "│  │  2. Similarity search in Vector Store                │  │\n",
    "│  │     (Using Mosaic AI Vector Search)                  │  │\n",
    "│  │  3. Retrieve top-k relevant chunks                    │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Prompt Augmentation                                        │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  Context: [Retrieved chunks]                         │  │\n",
    "│  │  Question: [User query]                              │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  Generation                                                 │\n",
    "│  ┌──────────────────────────────────────────────────────┐  │\n",
    "│  │  LLM generates response                              │  │\n",
    "│  │  (Using Mosaic AI Model Serving)                    │  │\n",
    "│  └──────────────────────────────────────────────────────┘  │\n",
    "└──────┬───────────────────────────────────────────────────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌──────────────┐\n",
    "│   Answer     │  \"Based on our policy document...\"\n",
    "└──────────────┘\n",
    "```\n",
    "\n",
    "### Databricks Features in RAG Architecture\n",
    "\n",
    "1. **Document Embedding**:\n",
    "   - **Mosaic AI Model Serving**: Host embedding models (BGE, OpenAI ada-002, custom models)\n",
    "   - **Mosaic AI Vector Search**: Store and search embeddings\n",
    "\n",
    "2. **Query Processing**:\n",
    "   - **Mosaic AI Model Serving**: Convert queries to embeddings\n",
    "   - **Mosaic AI Vector Search**: Perform similarity search\n",
    "\n",
    "3. **Generation**:\n",
    "   - **Mosaic AI Model Serving**: Host LLMs for response generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17dfbf1d-bc69-4e67-b2f2-924addf8988a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Benefits of RAG Architecture\n",
    "\n",
    "### 7.1 Up-to-Date and Accurate Responses\n",
    "\n",
    "**Benefit**: RAG enables access to current information\n",
    "\n",
    "**How**:\n",
    "- Knowledge base can be updated regularly\n",
    "- No need to retrain models\n",
    "- Real-time data integration possible\n",
    "\n",
    "**Example**: Stock prices, news, product catalogs\n",
    "\n",
    "### 7.2 Reducing Inaccurate Responses or Hallucinations\n",
    "\n",
    "**Benefit**: Grounding responses in retrieved documents reduces fabrication\n",
    "\n",
    "**How**:\n",
    "- Responses are based on actual documents\n",
    "- Model can cite sources\n",
    "- Easier to verify accuracy\n",
    "\n",
    "**Research**: Studies show RAG reduces hallucinations by 30-50% compared to base models\n",
    "\n",
    "### 7.3 Domain-Specific Contextualization\n",
    "\n",
    "**Benefit**: Adapt to any domain without model retraining\n",
    "\n",
    "**How**:\n",
    "- Add domain-specific documents to knowledge base\n",
    "- Model uses domain context in generation\n",
    "- No fine-tuning required\n",
    "\n",
    "**Example**: Medical, legal, financial domains\n",
    "\n",
    "### 7.4 Efficiency and Cost Effectiveness\n",
    "\n",
    "**Benefits**:\n",
    "- **No Fine-tuning**: Use pre-trained models\n",
    "- **Selective Context**: Only relevant information in prompts\n",
    "- **Reusable Infrastructure**: Same architecture for multiple use cases\n",
    "- **Lower Token Costs**: Smaller, focused contexts\n",
    "\n",
    "**Cost Comparison**:\n",
    "- Fine-tuning: High upfront cost, fixed knowledge\n",
    "- RAG: Lower per-query cost, updatable knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f7ef2fa-e394-4de4-8c33-680e7bf1a82f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. Mapping RAG Workflow to Databricks Features\n",
    "\n",
    "### Databricks RAG Components\n",
    "\n",
    "| RAG Component | Databricks Feature | Purpose |\n",
    "|--------------|-------------------|---------|\n",
    "| **Find Relevant Context** | Mosaic AI Vector Search | Similarity search in vector database |\n",
    "| **Generate Response** | Mosaic AI Model Serving | Host LLMs for generation |\n",
    "| **Serve RAG Chain** | Mosaic AI Model Serving | End-to-end RAG application deployment |\n",
    "| **Document Embedding** | Mosaic AI Model Serving | Convert documents to embeddings |\n",
    "| **Data Storage** | Delta Lake | Store documents and metadata |\n",
    "| **Data Governance** | Unity Catalog | Manage access and lineage |\n",
    "\n",
    "### Integration Flow\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│              Databricks RAG Stack                            │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                              │\n",
    "│  Delta Lake (Storage)                                        │\n",
    "│       │                                                      │\n",
    "│       ▼                                                      │\n",
    "│  Unity Catalog (Governance)                                 │\n",
    "│       │                                                      │\n",
    "│       ▼                                                      │\n",
    "│  Mosaic AI Model Serving (Embeddings)                       │\n",
    "│       │                                                      │\n",
    "│       ▼                                                      │\n",
    "│  Mosaic AI Vector Search (Retrieval)                        │\n",
    "│       │                                                      │\n",
    "│       ▼                                                      │\n",
    "│  Mosaic AI Model Serving (Generation)                       │\n",
    "│       │                                                      │\n",
    "│       ▼                                                      │\n",
    "│  RAG Application (Deployed)                                 │\n",
    "│                                                              │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Advantages of Databricks RAG Stack\n",
    "\n",
    "1. **Unified Platform**: All components in one place\n",
    "2. **Lakehouse Integration**: Direct access to data lake\n",
    "3. **Governance**: Unity Catalog for security and compliance\n",
    "4. **Scalability**: Built for enterprise scale\n",
    "5. **Zero Operational Overhead**: Managed services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a13c1ab-91bb-4d73-ac78-2781a9eeba91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 9. Demonstration: In-Context Learning with AI Playground\n",
    "\n",
    "### Hands-On Exercise\n",
    "\n",
    "**Objective**: Experience how context improves LLM responses\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "1. **Test without context**:\n",
    "   - Ask a question about recent events\n",
    "   - Observe limitations\n",
    "\n",
    "2. **Test with context**:\n",
    "   - Provide relevant documents\n",
    "   - Ask the same question\n",
    "   - Compare results\n",
    "\n",
    "**Key Observations**:\n",
    "- Context enables accurate, specific answers\n",
    "- Without context, models rely on training knowledge (may be outdated)\n",
    "- With context, responses are grounded and verifiable\n",
    "\n",
    "### Example Scenario\n",
    "\n",
    "**Without Context**:\n",
    "```\n",
    "Q: What is our company's refund policy?\n",
    "A: [Generic or incorrect response based on training data]\n",
    "```\n",
    "\n",
    "**With Context**:\n",
    "```\n",
    "Context: [Company refund policy document]\n",
    "\n",
    "Q: What is our company's refund policy?\n",
    "A: [Accurate response based on provided document]\n",
    "```\n",
    "\n",
    "**Takeaway**: This demonstrates the core value proposition of RAG!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e5746a1-9c0e-404e-b864-a156c44600a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Language models learn** through pre-training, fine-tuning, and context passing\n",
    "2. **RAG solves the knowledge gap** between model training and real-world needs\n",
    "3. **RAG is a pattern** combining retrieval, augmentation, and generation\n",
    "4. **RAG enables** up-to-date, accurate, domain-specific responses\n",
    "5. **Databricks provides** integrated RAG infrastructure (Vector Search, Model Serving)\n",
    "\n",
    "### Next Module: Data Preparation for RAG\n",
    "\n",
    "In the next module, we'll dive deep into:\n",
    "- Why data preparation is critical for RAG success\n",
    "- Data extraction and chunking strategies\n",
    "- Embedding model selection\n",
    "- Handling complex documents\n",
    "- Databricks tools for data preparation\n",
    "\n",
    "**Remember**: The quality of your RAG system depends heavily on how well you prepare your data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21f5d77b-0ffe-4934-ac60-65aaa4b6106f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Exercise 1**: Explain the knowledge gap problem and how RAG addresses it\n",
    "2. **Exercise 2**: Identify 3 use cases where RAG would be beneficial in your domain\n",
    "3. **Exercise 3**: Map the RAG workflow components to Databricks features\n",
    "4. **Exercise 4**: Compare RAG with fine-tuning - when would you use each?\n",
    "5. **Exercise 5**: Design a simple RAG architecture diagram for a specific use case\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "02_Introduction_to_RAG",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
