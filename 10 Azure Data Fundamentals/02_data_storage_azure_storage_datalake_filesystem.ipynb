{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 02 - Data Storage: Azure Storage, Data Lake, File System\n",
        "\n",
        "## Overview\n",
        "\n",
        "This module covers Azure storage services that form the foundation of data engineering solutions. Understanding storage options is crucial for designing efficient and cost-effective data architectures.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this module, you will understand:\n",
        "- Azure Storage Account and its services (Blob, File, Queue, Table)\n",
        "- Azure Data Lake Storage Gen2 and its capabilities\n",
        "- Hierarchical namespace and file system concepts\n",
        "- When to use Azure Storage vs Data Lake Storage\n",
        "- Storage account types and performance tiers\n",
        "- Best practices for organizing data in storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure Storage Account\n",
        "\n",
        "**Azure Storage Account** is a container that groups a set of Azure Storage services together. It provides a unique namespace for your data in Azure.\n",
        "\n",
        "### Storage Account Services\n",
        "\n",
        "A storage account can contain four types of data services:\n",
        "\n",
        "1. **Blob Storage**: Object storage for unstructured data (text, binary, images, videos)\n",
        "2. **File Storage**: Managed file shares accessible via SMB protocol\n",
        "3. **Queue Storage**: Message queuing for application communication\n",
        "4. **Table Storage**: NoSQL key-value store for structured data\n",
        "\n",
        "### Storage Account Types\n",
        "\n",
        "#### General Purpose v2 (GPv2)\n",
        "- **Recommended** for most scenarios\n",
        "- Supports all storage services\n",
        "- Best price-performance balance\n",
        "- Supports hot, cool, and archive access tiers\n",
        "\n",
        "#### General Purpose v1 (GPv1)\n",
        "- Legacy account type\n",
        "- Still supported but not recommended for new accounts\n",
        "- Limited features compared to v2\n",
        "\n",
        "#### Blob Storage Account\n",
        "- Legacy account type\n",
        "- Only supports blob storage\n",
        "- Not recommended for new deployments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blob Storage\n",
        "\n",
        "**Azure Blob Storage** is Microsoft's object storage solution for the cloud. It's optimized for storing massive amounts of unstructured data.\n",
        "\n",
        "### Blob Types\n",
        "\n",
        "1. **Block Blobs**\n",
        "   - For text and binary data\n",
        "   - Up to ~4.75 TB per blob\n",
        "   - Best for streaming and cloud-native applications\n",
        "   - Most common type for data engineering\n",
        "\n",
        "2. **Append Blobs**\n",
        "   - Optimized for append operations\n",
        "   - Good for logging scenarios\n",
        "   - Up to ~195 GB per blob\n",
        "\n",
        "3. **Page Blobs**\n",
        "   - For random read/write operations\n",
        "   - Used for VHD files (virtual machine disks)\n",
        "   - Up to 8 TB per blob\n",
        "\n",
        "### Blob Storage Structure\n",
        "\n",
        "```\n",
        "Storage Account\n",
        "└── Container (like a folder)\n",
        "    └── Blob (the actual file)\n",
        "```\n",
        "\n",
        "### Access Tiers\n",
        "\n",
        "- **Hot**: Frequently accessed data (lowest storage cost, highest access cost)\n",
        "- **Cool**: Infrequently accessed data (lower access cost, higher storage cost)\n",
        "- **Archive**: Rarely accessed data (lowest storage cost, highest access cost, requires rehydration)\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- Data lakes and big data analytics\n",
        "- Backup and disaster recovery\n",
        "- Media storage and streaming\n",
        "- Log file storage\n",
        "- Raw data storage before processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure Data Lake Storage Gen2\n",
        "\n",
        "**Azure Data Lake Storage Gen2 (ADLS Gen2)** is built on Azure Blob Storage and adds a hierarchical namespace, making it optimized for big data analytics workloads.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "1. **Hierarchical Namespace**\n",
        "   - Organizes objects/files into a directory hierarchy\n",
        "   - Enables file system semantics (directories, subdirectories)\n",
        "   - Improves performance for analytics operations\n",
        "\n",
        "2. **Hadoop Compatible**\n",
        "   - Works with Hadoop Distributed File System (HDFS)\n",
        "   - Supports Apache Spark, Hive, Presto, and other analytics engines\n",
        "   - Can be used as primary storage for HDInsight, Databricks, Synapse\n",
        "\n",
        "3. **ACL (Access Control Lists)**\n",
        "   - Fine-grained access control at file and directory level\n",
        "   - POSIX-compliant permissions\n",
        "   - Supports both Azure RBAC and ACLs\n",
        "\n",
        "4. **Optimized for Analytics**\n",
        "   - Better performance for large-scale analytics\n",
        "   - Supports atomic operations\n",
        "   - Optimized for parallel processing\n",
        "\n",
        "### ADLS Gen2 Structure\n",
        "\n",
        "```\n",
        "Storage Account (with hierarchical namespace enabled)\n",
        "└── File System (Container)\n",
        "    └── Directory\n",
        "        └── Subdirectory\n",
        "            └── File\n",
        "```\n",
        "\n",
        "### When to Use ADLS Gen2\n",
        "\n",
        "✅ Big data analytics workloads\n",
        "✅ Need for hierarchical organization\n",
        "✅ Working with Spark, Hive, or other analytics tools\n",
        "✅ Require fine-grained access control\n",
        "✅ Processing large files in parallel\n",
        "\n",
        "### When to Use Regular Blob Storage\n",
        "\n",
        "✅ Simple object storage needs\n",
        "✅ Not using analytics tools\n",
        "✅ Cost optimization for simple storage\n",
        "✅ Legacy applications that don't support ADLS Gen2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## File System Concepts\n",
        "\n",
        "### Hierarchical Namespace\n",
        "\n",
        "**Hierarchical namespace** organizes blob data into a directory structure, similar to a file system on your computer.\n",
        "\n",
        "#### Without Hierarchical Namespace (Blob Storage)\n",
        "```\n",
        "https://storageaccount.blob.core.windows.net/container/blob1\n",
        "https://storageaccount.blob.core.windows.net/container/blob2\n",
        "https://storageaccount.blob.core.windows.net/container/blob3\n",
        "```\n",
        "- Flat structure\n",
        "- No true directories\n",
        "- Slower for directory operations\n",
        "\n",
        "#### With Hierarchical Namespace (ADLS Gen2)\n",
        "```\n",
        "https://storageaccount.dfs.core.windows.net/filesystem/sales/2024/january/data.csv\n",
        "https://storageaccount.dfs.core.windows.net/filesystem/sales/2024/february/data.csv\n",
        "https://storageaccount.dfs.core.windows.net/filesystem/marketing/2024/data.csv\n",
        "```\n",
        "- Directory structure: `/sales/2024/january/`\n",
        "- True directories and subdirectories\n",
        "- Faster directory operations and analytics\n",
        "\n",
        "### File System Operations\n",
        "\n",
        "Common operations in a hierarchical namespace:\n",
        "- **Create Directory**: Organize files into folders\n",
        "- **Rename Directory**: Reorganize structure\n",
        "- **Delete Directory**: Remove entire folder trees\n",
        "- **List Directory**: Get contents of a directory\n",
        "- **Move/Rename Files**: Reorganize files within structure\n",
        "\n",
        "### Benefits for Data Engineering\n",
        "\n",
        "1. **Organization**: Logical structure matching business needs\n",
        "2. **Performance**: Faster operations on directories\n",
        "3. **Compatibility**: Works with tools expecting file systems\n",
        "4. **Partitioning**: Natural partitioning by date, region, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storage Account Configuration\n",
        "\n",
        "### Performance Tiers\n",
        "\n",
        "#### Standard Performance\n",
        "- Uses hard disk drives (HDD)\n",
        "- Lower cost\n",
        "- Good for bulk data, backups, archives\n",
        "- Suitable for data accessed infrequently\n",
        "\n",
        "#### Premium Performance\n",
        "- Uses solid-state drives (SSD)\n",
        "- Higher cost, better performance\n",
        "- Good for frequently accessed data\n",
        "- Lower latency, higher throughput\n",
        "\n",
        "### Redundancy Options\n",
        "\n",
        "1. **Locally Redundant Storage (LRS)**\n",
        "   - Data replicated 3 times within a single datacenter\n",
        "   - Lowest cost, lowest durability\n",
        "   - 99.999999999% (11 9's) durability\n",
        "\n",
        "2. **Zone-Redundant Storage (ZRS)**\n",
        "   - Data replicated across 3 availability zones in a region\n",
        "   - Higher durability than LRS\n",
        "   - Protects against datacenter failures\n",
        "\n",
        "3. **Geo-Redundant Storage (GRS)**\n",
        "   - Data replicated to a secondary region\n",
        "   - 99.9999999999999% (16 9's) durability\n",
        "   - Protects against regional disasters\n",
        "\n",
        "4. **Geo-Zone-Redundant Storage (GZRS)**\n",
        "   - Combines ZRS in primary region with GRS\n",
        "   - Highest durability and availability\n",
        "   - Best for mission-critical data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Organization Best Practices\n",
        "\n",
        "### Folder Structure Patterns\n",
        "\n",
        "#### Pattern 1: Date-Based Partitioning\n",
        "```\n",
        "/data/\n",
        "  /raw/\n",
        "    /2024/\n",
        "      /01/\n",
        "        /01/  (day)\n",
        "          data.csv\n",
        "      /02/\n",
        "  /processed/\n",
        "    /2024/\n",
        "      /01/\n",
        "```\n",
        "\n",
        "#### Pattern 2: Subject Area Partitioning\n",
        "```\n",
        "/data/\n",
        "  /sales/\n",
        "    /raw/\n",
        "    /processed/\n",
        "  /marketing/\n",
        "    /raw/\n",
        "    /processed/\n",
        "  /finance/\n",
        "    /raw/\n",
        "    /processed/\n",
        "```\n",
        "\n",
        "#### Pattern 3: Hybrid (Recommended)\n",
        "```\n",
        "/data/\n",
        "  /sales/\n",
        "    /raw/\n",
        "      /2024/\n",
        "        /01/\n",
        "          sales_2024_01_01.csv\n",
        "    /processed/\n",
        "      /2024/\n",
        "        /01/\n",
        "          sales_daily_summary_2024_01.parquet\n",
        "  /marketing/\n",
        "    /raw/\n",
        "      /2024/\n",
        "        /01/\n",
        "```\n",
        "\n",
        "### Naming Conventions\n",
        "\n",
        "✅ **Good Practices:**\n",
        "- Use lowercase letters and hyphens: `sales-data-2024-01-01.csv`\n",
        "- Include date in filename: `data_YYYY_MM_DD.csv`\n",
        "- Be descriptive: `customer-transactions-raw.csv`\n",
        "- Use consistent formats across projects\n",
        "\n",
        "❌ **Avoid:**\n",
        "- Spaces in names: `sales data.csv`\n",
        "- Special characters: `sales@data#2024.csv`\n",
        "- Inconsistent formats: `SalesData_2024-1-1.csv` vs `sales_data_2024_01_01.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Working with Azure Storage using Python SDK\n",
        "# Note: This is a conceptual example. In practice, you'll need:\n",
        "# - Azure Storage Account credentials\n",
        "# - azure-storage-blob package installed\n",
        "# - Proper authentication configured\n",
        "\n",
        "# Uncomment and install if needed:\n",
        "# !pip install azure-storage-blob azure-identity\n",
        "\n",
        "\"\"\"\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import os\n",
        "\n",
        "# Authentication (using DefaultAzureCredential)\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Storage account URL\n",
        "storage_account_url = \"https://<storageaccountname>.blob.core.windows.net\"\n",
        "\n",
        "# Create BlobServiceClient\n",
        "blob_service_client = BlobServiceClient(\n",
        "    account_url=storage_account_url,\n",
        "    credential=credential\n",
        ")\n",
        "\n",
        "# Create a container (if it doesn't exist)\n",
        "container_name = \"data-lake\"\n",
        "try:\n",
        "    container_client = blob_service_client.create_container(container_name)\n",
        "    print(f\"Container '{container_name}' created successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Container may already exist: {e}\")\n",
        "\n",
        "# Upload a file\n",
        "local_file_path = \"sample_data.csv\"\n",
        "blob_name = \"raw/2024/01/sample_data.csv\"\n",
        "blob_client = blob_service_client.get_blob_client(\n",
        "    container=container_name, \n",
        "    blob=blob_name\n",
        ")\n",
        "\n",
        "with open(local_file_path, \"rb\") as data:\n",
        "    blob_client.upload_blob(data, overwrite=True)\n",
        "    print(f\"File uploaded to {blob_name}\")\n",
        "\n",
        "# List blobs in a directory\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blobs = container_client.list_blobs(name_starts_with=\"raw/2024/01/\")\n",
        "for blob in blobs:\n",
        "    print(f\"Blob: {blob.name}, Size: {blob.size} bytes\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"This is a conceptual example.\")\n",
        "print(\"To use Azure Storage SDK, you need:\")\n",
        "print(\"1. Azure Storage Account\")\n",
        "print(\"2. Authentication credentials\")\n",
        "print(\"3. azure-storage-blob package installed\")\n",
        "print(\"\\nKey concepts demonstrated:\")\n",
        "print(\"- Creating containers\")\n",
        "print(\"- Uploading files\")\n",
        "print(\"- Listing blobs\")\n",
        "print(\"- Organizing data in hierarchical structure\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Azure Storage vs Data Lake Storage Gen2\n",
        "\n",
        "### Comparison Table\n",
        "\n",
        "| Feature | Azure Blob Storage | Azure Data Lake Storage Gen2 |\n",
        "|---------|-------------------|------------------------------|\n",
        "| **Namespace** | Flat | Hierarchical |\n",
        "| **File System Semantics** | Limited | Full support |\n",
        "| **Analytics Performance** | Good | Optimized |\n",
        "| **ACL Support** | Container-level | File and directory level |\n",
        "| **Hadoop Compatibility** | Via WASB | Native HDFS |\n",
        "| **Cost** | Lower | Slightly higher |\n",
        "| **Use Case** | General object storage | Big data analytics |\n",
        "\n",
        "### Decision Matrix\n",
        "\n",
        "**Choose Azure Blob Storage when:**\n",
        "- Simple object storage needs\n",
        "- Not using analytics tools (Spark, Hive)\n",
        "- Cost is primary concern\n",
        "- Legacy applications\n",
        "\n",
        "**Choose ADLS Gen2 when:**\n",
        "- Big data analytics workloads\n",
        "- Need hierarchical organization\n",
        "- Using Spark, Databricks, Synapse\n",
        "- Require fine-grained access control\n",
        "- Processing large-scale data\n",
        "\n",
        "### Migration Path\n",
        "\n",
        "You can enable hierarchical namespace on an existing storage account (one-way operation):\n",
        "- Enables ADLS Gen2 features\n",
        "- Existing blobs remain accessible\n",
        "- Cannot be disabled once enabled\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## File Storage (Azure Files)\n",
        "\n",
        "**Azure Files** provides fully managed file shares in the cloud, accessible via Server Message Block (SMB) protocol.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **SMB Protocol**: Accessible like a network drive\n",
        "- **Mountable**: Can be mounted on Windows, Linux, macOS\n",
        "- **Shared Access**: Multiple users/applications can access simultaneously\n",
        "- **Snapshot Support**: Point-in-time backups\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- Lift and shift applications expecting file shares\n",
        "- Shared storage for multiple VMs\n",
        "- Development and testing environments\n",
        "- Content management systems\n",
        "- Application configuration storage\n",
        "\n",
        "### File Share Types\n",
        "\n",
        "1. **Standard File Shares**\n",
        "   - HDD-backed\n",
        "   - Lower cost\n",
        "   - Good for general-purpose file sharing\n",
        "\n",
        "2. **Premium File Shares**\n",
        "   - SSD-backed\n",
        "   - Higher performance\n",
        "   - Better for I/O-intensive workloads\n",
        "\n",
        "### Note for Data Engineering\n",
        "\n",
        "While Azure Files is useful for certain scenarios, **Blob Storage** and **ADLS Gen2** are more commonly used in data engineering pipelines due to:\n",
        "- Better integration with analytics tools\n",
        "- Lower cost for large-scale data\n",
        "- Optimized for batch processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storage Endpoints and URLs\n",
        "\n",
        "### Blob Storage Endpoints\n",
        "\n",
        "```\n",
        "https://<storageaccountname>.blob.core.windows.net/<container>/<blob>\n",
        "```\n",
        "\n",
        "Example:\n",
        "```\n",
        "https://mydatalake.blob.core.windows.net/raw-data/sales/2024/01/data.csv\n",
        "```\n",
        "\n",
        "### Data Lake Storage Gen2 Endpoints\n",
        "\n",
        "**Data Lake Storage (DFS) Endpoint:**\n",
        "```\n",
        "https://<storageaccountname>.dfs.core.windows.net/<filesystem>/<path>/<file>\n",
        "```\n",
        "\n",
        "**Blob Endpoint (also works):**\n",
        "```\n",
        "https://<storageaccountname>.blob.core.windows.net/<filesystem>/<path>/<file>\n",
        "```\n",
        "\n",
        "Example:\n",
        "```\n",
        "https://mydatalake.dfs.core.windows.net/data-lake/raw/sales/2024/01/data.csv\n",
        "```\n",
        "\n",
        "### Access Methods\n",
        "\n",
        "1. **Azure Portal**: Web-based interface\n",
        "2. **Azure Storage Explorer**: Desktop application\n",
        "3. **REST API**: Programmatic access\n",
        "4. **SDKs**: Python, .NET, Java, etc.\n",
        "5. **Command Line**: Azure CLI, PowerShell\n",
        "6. **Analytics Tools**: Spark, Hive, Synapse (via abfss:// protocol)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this module, we've covered:\n",
        "\n",
        "✅ Azure Storage Account and its services (Blob, File, Queue, Table)\n",
        "✅ Blob Storage types and access tiers\n",
        "✅ Azure Data Lake Storage Gen2 and hierarchical namespace\n",
        "✅ File system concepts and organization\n",
        "✅ Storage account types and performance tiers\n",
        "✅ Redundancy options for data durability\n",
        "✅ Data organization best practices\n",
        "✅ Comparison between Blob Storage and ADLS Gen2\n",
        "✅ Storage endpoints and access methods\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Azure Storage Account** is the foundation for storing data in Azure\n",
        "2. **Blob Storage** is ideal for unstructured data and object storage\n",
        "3. **ADLS Gen2** adds hierarchical namespace for better analytics performance\n",
        "4. **Hierarchical namespace** enables file system semantics and better organization\n",
        "5. **Choose storage type** based on your use case: simple storage vs analytics workloads\n",
        "6. **Organize data** using consistent folder structures and naming conventions\n",
        "7. **Consider redundancy** based on your durability and availability requirements\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Proceed to **Module 03: Data Ingestion** to learn about:\n",
        "- How to move data from sources to Azure\n",
        "- Batch vs streaming data ingestion\n",
        "- Azure Data Factory for data movement\n",
        "- Event Hubs for streaming data\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
