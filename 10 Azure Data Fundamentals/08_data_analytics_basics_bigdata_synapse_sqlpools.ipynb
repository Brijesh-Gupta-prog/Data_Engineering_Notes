{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 08 - Data Analytics Basics: Big Data, Synapse Workspace, SQL Pools\n",
        "\n",
        "## Overview\n",
        "\n",
        "This module covers big data concepts, the 3-Vs of big data, distributed querying, and how Azure Synapse Analytics addresses big data analytics challenges.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this module, you will understand:\n",
        "- What is Big Data and why it matters\n",
        "- The 3-Vs of Big Data (Volume, Velocity, Variety)\n",
        "- Distributed querying concepts\n",
        "- Synapse Workspace architecture\n",
        "- Dedicated SQL Pools for distributed analytics\n",
        "- Serverless SQL Pools for on-demand querying\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Big Data\n",
        "\n",
        "**Big Data** refers to datasets that are too large or complex for traditional data processing applications to handle effectively.\n",
        "\n",
        "### Why Big Data Matters\n",
        "\n",
        "- **Data Explosion**: Organizations generate massive amounts of data\n",
        "- **Business Value**: Hidden insights in large datasets\n",
        "- **Competitive Advantage**: Data-driven decisions\n",
        "- **New Opportunities**: New business models and services\n",
        "\n",
        "### Traditional vs Big Data\n",
        "\n",
        "| Aspect | Traditional Data | Big Data |\n",
        "|--------|----------------|----------|\n",
        "| **Volume** | GB to TB | TB to PB+ |\n",
        "| **Processing** | Single server | Distributed clusters |\n",
        "| **Tools** | SQL databases | Hadoop, Spark, NoSQL |\n",
        "| **Storage** | Relational databases | Data lakes, distributed storage |\n",
        "| **Analysis** | Structured queries | Complex analytics |\n",
        "\n",
        "### Big Data Challenges\n",
        "\n",
        "- **Storage**: Where to store massive datasets\n",
        "- **Processing**: How to process efficiently\n",
        "- **Analysis**: How to extract insights\n",
        "- **Cost**: Managing costs at scale\n",
        "- **Skills**: Need specialized skills\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The 3-Vs of Big Data\n",
        "\n",
        "The 3-Vs framework describes the characteristics of big data:\n",
        "\n",
        "### 1. Volume\n",
        "\n",
        "**Volume** refers to the massive amount of data being generated and stored.\n",
        "\n",
        "**Examples:**\n",
        "- Social media: Billions of posts, images, videos\n",
        "- IoT devices: Millions of sensors generating data continuously\n",
        "- E-commerce: Millions of transactions daily\n",
        "- Logs: Terabytes of application logs\n",
        "\n",
        "**Challenges:**\n",
        "- Storage capacity\n",
        "- Processing power\n",
        "- Network bandwidth\n",
        "- Cost management\n",
        "\n",
        "### 2. Velocity\n",
        "\n",
        "**Velocity** refers to the speed at which data is generated and needs to be processed.\n",
        "\n",
        "**Examples:**\n",
        "- Real-time transactions\n",
        "- Streaming data from IoT\n",
        "- Social media feeds\n",
        "- Stock market data\n",
        "\n",
        "**Challenges:**\n",
        "- Real-time processing\n",
        "- Low latency requirements\n",
        "- Stream processing\n",
        "- Event-driven architectures\n",
        "\n",
        "### 3. Variety\n",
        "\n",
        "**Variety** refers to the different types and formats of data.\n",
        "\n",
        "**Types:**\n",
        "- **Structured**: Relational databases, CSV\n",
        "- **Semi-structured**: JSON, XML\n",
        "- **Unstructured**: Text, images, videos, audio\n",
        "\n",
        "**Challenges:**\n",
        "- Multiple data formats\n",
        "- Schema evolution\n",
        "- Data integration\n",
        "- Unified analytics\n",
        "\n",
        "### Additional V's (Sometimes Mentioned)\n",
        "\n",
        "- **Veracity**: Data quality and trustworthiness\n",
        "- **Value**: Extracting business value from data\n",
        "- **Variability**: Changing data structures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distributed Querying\n",
        "\n",
        "**Distributed Querying** is the ability to query data that is distributed across multiple nodes or servers.\n",
        "\n",
        "### Why Distributed Querying?\n",
        "\n",
        "- **Scale**: Handle data too large for single server\n",
        "- **Performance**: Parallel processing for faster queries\n",
        "- **Availability**: Fault tolerance and high availability\n",
        "- **Cost**: Use commodity hardware\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "#### 1. Data Distribution\n",
        "\n",
        "**How data is spread across nodes:**\n",
        "\n",
        "- **Hash Distribution**: Data distributed by hash of key\n",
        "- **Round-Robin**: Data distributed evenly\n",
        "- **Replicated**: Full copy on each node\n",
        "\n",
        "#### 2. Query Parallelism\n",
        "\n",
        "**Processing queries in parallel:**\n",
        "\n",
        "- **Partition Pruning**: Only read relevant partitions\n",
        "- **Parallel Execution**: Multiple nodes process simultaneously\n",
        "- **Result Aggregation**: Combine results from nodes\n",
        "\n",
        "#### 3. Massively Parallel Processing (MPP)\n",
        "\n",
        "**MPP Architecture:**\n",
        "- Control node coordinates query execution\n",
        "- Compute nodes process data in parallel\n",
        "- Results aggregated and returned\n",
        "\n",
        "### MPP Architecture\n",
        "\n",
        "```\n",
        "Control Node\n",
        "├── Query Parser\n",
        "├── Query Optimizer\n",
        "└── Query Coordinator\n",
        "    │\n",
        "    ├── Compute Node 1 ──┐\n",
        "    ├── Compute Node 2 ──┤\n",
        "    ├── Compute Node 3 ──┼── Process in Parallel\n",
        "    └── Compute Node N ──┘\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synapse Workspace for Big Data Analytics\n",
        "\n",
        "**Azure Synapse Workspace** provides a unified platform for big data analytics.\n",
        "\n",
        "### Components for Big Data\n",
        "\n",
        "1. **Dedicated SQL Pool**: MPP data warehouse\n",
        "2. **Serverless SQL Pool**: On-demand querying\n",
        "3. **Spark Pools**: Big data processing\n",
        "4. **Data Lake Integration**: Native ADLS Gen2 integration\n",
        "5. **Data Factory**: ETL/ELT capabilities\n",
        "\n",
        "### How Synapse Addresses 3-Vs\n",
        "\n",
        "#### Volume\n",
        "- **Dedicated SQL Pool**: Handles petabytes of data\n",
        "- **Spark Pools**: Process large datasets\n",
        "- **Data Lake**: Unlimited storage\n",
        "\n",
        "#### Velocity\n",
        "- **Stream Analytics**: Real-time processing\n",
        "- **Spark Streaming**: Stream processing\n",
        "- **Event-driven pipelines**: Process as data arrives\n",
        "\n",
        "#### Variety\n",
        "- **Multiple Engines**: SQL, Spark, Data Factory\n",
        "- **File Formats**: CSV, JSON, Parquet, etc.\n",
        "- **Unified Interface**: Synapse Studio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dedicated SQL Pools - Distributed Analytics\n",
        "\n",
        "**Dedicated SQL Pools** use MPP architecture for distributed analytics.\n",
        "\n",
        "### MPP Architecture in Dedicated SQL Pool\n",
        "\n",
        "- **Control Node**: Coordinates query execution\n",
        "- **Compute Nodes**: Process data in parallel (60 nodes max)\n",
        "- **Storage**: Distributed across nodes\n",
        "- **Data Movement**: Automatic data movement for joins\n",
        "\n",
        "### Distribution Strategies\n",
        "\n",
        "#### 1. Hash Distribution\n",
        "- Data distributed by hash of distribution key\n",
        "- Good for joins on distribution key\n",
        "- Example: `DISTRIBUTION = HASH(CustomerID)`\n",
        "\n",
        "#### 2. Round-Robin Distribution\n",
        "- Data distributed evenly across nodes\n",
        "- Good when no clear distribution key\n",
        "- Example: `DISTRIBUTION = ROUND_ROBIN`\n",
        "\n",
        "#### 3. Replicated Distribution\n",
        "- Full copy of table on each node\n",
        "- Good for small dimension tables\n",
        "- Example: `DISTRIBUTION = REPLICATE`\n",
        "\n",
        "### Performance Optimization\n",
        "\n",
        "- **Columnstore Indexes**: Compressed, columnar storage\n",
        "- **Statistics**: Query optimizer uses statistics\n",
        "- **Partitioning**: Partition large tables\n",
        "- **Workload Management**: Resource allocation\n",
        "\n",
        "### Example: Distributed Query\n",
        "\n",
        "```sql\n",
        "-- Table with hash distribution\n",
        "CREATE TABLE Sales (\n",
        "    SaleID INT,\n",
        "    CustomerID INT,\n",
        "    Amount DECIMAL(10,2)\n",
        ")\n",
        "WITH (\n",
        "    DISTRIBUTION = HASH(CustomerID),\n",
        "    CLUSTERED COLUMNSTORE INDEX\n",
        ");\n",
        "\n",
        "-- Query runs in parallel across nodes\n",
        "SELECT CustomerID, SUM(Amount) as Total\n",
        "FROM Sales\n",
        "GROUP BY CustomerID;\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serverless SQL Pools - On-Demand Querying\n",
        "\n",
        "**Serverless SQL Pools** provide on-demand querying of data in Data Lake.\n",
        "\n",
        "### Characteristics\n",
        "\n",
        "- **No Infrastructure**: No servers to manage\n",
        "- **Pay-per-Query**: Pay only for data processed\n",
        "- **Query Files Directly**: Query files without loading\n",
        "- **Automatic Scaling**: Scales automatically\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "✅ **Exploratory Analysis**: Quick data exploration\n",
        "✅ **Ad-hoc Queries**: One-off queries\n",
        "✅ **Data Lake Querying**: Query files in Data Lake\n",
        "✅ **Cost-Effective**: Pay only for what you use\n",
        "\n",
        "### Querying Data Lake\n",
        "\n",
        "```sql\n",
        "-- Query CSV file\n",
        "SELECT *\n",
        "FROM OPENROWSET(\n",
        "    BULK 'https://storage.dfs.core.windows.net/container/data.csv',\n",
        "    FORMAT = 'CSV',\n",
        "    PARSER_VERSION = '2.0',\n",
        "    HEADER_ROW = TRUE\n",
        ") AS [result];\n",
        "\n",
        "-- Query Parquet files\n",
        "SELECT *\n",
        "FROM OPENROWSET(\n",
        "    BULK 'https://storage.dfs.core.windows.net/container/*.parquet',\n",
        "    FORMAT = 'PARQUET'\n",
        ") AS [result];\n",
        "```\n",
        "\n",
        "### External Tables\n",
        "\n",
        "```sql\n",
        "-- Create external data source\n",
        "CREATE EXTERNAL DATA SOURCE DataLakeSource\n",
        "WITH (\n",
        "    LOCATION = 'https://storage.dfs.core.windows.net/container/'\n",
        ");\n",
        "\n",
        "-- Create external table\n",
        "CREATE EXTERNAL TABLE SalesExternal\n",
        "WITH (\n",
        "    LOCATION = 'sales/',\n",
        "    DATA_SOURCE = DataLakeSource,\n",
        "    FILE_FORMAT = ParquetFormat\n",
        ") AS\n",
        "SELECT * FROM OPENROWSET(...);\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this module, we've covered:\n",
        "\n",
        "✅ Introduction to Big Data\n",
        "✅ The 3-Vs of Big Data (Volume, Velocity, Variety)\n",
        "✅ Distributed querying concepts\n",
        "✅ MPP architecture\n",
        "✅ Synapse Workspace for big data analytics\n",
        "✅ Dedicated SQL Pools for distributed analytics\n",
        "✅ Serverless SQL Pools for on-demand querying\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Big Data** is characterized by Volume, Velocity, and Variety\n",
        "2. **Distributed Querying** enables processing of large datasets\n",
        "3. **MPP Architecture** processes queries in parallel\n",
        "4. **Dedicated SQL Pool** provides enterprise data warehousing\n",
        "5. **Serverless SQL Pool** provides cost-effective on-demand querying\n",
        "6. **Synapse Workspace** unifies big data analytics\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Proceed to **Module 09: Access Control & Security** to learn about:\n",
        "- RBAC (Role-Based Access Control)\n",
        "- SAS (Shared Access Signatures)\n",
        "- Azure Key Vault\n",
        "- Security best practices\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
