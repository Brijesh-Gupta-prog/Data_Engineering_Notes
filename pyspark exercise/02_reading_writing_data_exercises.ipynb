{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWhkG5r5ITPl"
      },
      "source": [
        "# Module 02 - Reading & Writing Data - Exercises## InstructionsThis notebook contains exercises based on the concepts learned in Module 02.- Complete each exercise in the provided code cells- Run the data setup cells first to generate/create necessary data- Test your solutions by running the verification cells (if provided)- Refer back to the main module notebook if you need help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_M5kf7CITPm"
      },
      "source": [
        "## Data Setup\n",
        "\n",
        "Run the cells below to set up the data needed for the exercises.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA4dnjMGITPm",
        "outputId": "56bdb27b-3099-4e2e-9a4c-5fd86a9a3bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession created successfully!\n",
            "Data directory: /data\n",
            "Created CSV file: ../data/exercise_data.csv\n",
            "Created JSON file: ../data/exercise_data.json\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField, StringType,\n",
        "    IntegerType, DoubleType, DateType\n",
        ")\n",
        "from pyspark.sql.functions import col, when, lit\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(f\"Module 1 Exercises\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Set data directory\n",
        "data_dir = \"../data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "print(\"SparkSession created successfully!\")\n",
        "print(f\"Data directory: {os.path.abspath(data_dir)}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Generate sample CSV data\n",
        "# -----------------------------\n",
        "csv_data = {\n",
        "    \"id\": range(1, 1001),\n",
        "    \"name\": [f\"Person_{i}\" for i in range(1, 1001)],\n",
        "    \"age\": np.random.randint(20, 60, 1000),\n",
        "    \"city\": np.random.choice(\n",
        "        [\"NYC\", \"LA\", \"Chicago\", \"Houston\", \"Phoenix\"], 1000\n",
        "    ),\n",
        "    \"salary\": np.random.randint(40000, 120000, 1000)\n",
        "}\n",
        "\n",
        "df_csv = pd.DataFrame(csv_data)\n",
        "df_csv.to_csv(f\"{data_dir}/exercise_data.csv\", index=False)\n",
        "\n",
        "print(f\"Created CSV file: {data_dir}/exercise_data.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# Generate sample JSON data\n",
        "# -----------------------------\n",
        "json_data = [\n",
        "    {\n",
        "        \"id\": i,\n",
        "        \"product\": f\"Product_{i}\",\n",
        "        \"price\": round(np.random.uniform(10, 100), 2),\n",
        "        \"category\": np.random.choice(\n",
        "            [\"Electronics\", \"Clothing\", \"Food\", \"Books\"], 1\n",
        "        )[0]\n",
        "    }\n",
        "    for i in range(1, 501)\n",
        "]\n",
        "\n",
        "with open(f\"{data_dir}/exercise_data.json\", \"w\") as f:\n",
        "    json.dump(json_data, f, indent=2)\n",
        "\n",
        "print(f\"Created JSON file: {data_dir}/exercise_data.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiezMlR4ITPn"
      },
      "source": [
        "## ExercisesComplete the following exercises based on the concepts from Module 02."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0oJo-nuITPn"
      },
      "source": [
        "### Exercise 1: Read CSV FileRead the 'exercise_data.csv' file from the data directory and display the first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLJYhDxpITPo",
        "outputId": "1c42f4f4-c1f5-4cd0-f857-881e9913336c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---+-------+------+\n",
            "| id|    name|age|   city|salary|\n",
            "+---+--------+---+-------+------+\n",
            "|  1|Person_1| 20|Chicago| 85163|\n",
            "|  2|Person_2| 31|Phoenix|118464|\n",
            "|  3|Person_3| 50|Chicago| 94327|\n",
            "|  4|Person_4| 42|     LA|107071|\n",
            "|  5|Person_5| 47|Phoenix|118236|\n",
            "+---+--------+---+-------+------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "df_1 = spark.read.csv(f\"{data_dir}/exercise_data.csv\",header=True)\n",
        "df_1.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIvVDfSsITPo"
      },
      "source": [
        "### Exercise 2: Read JSON FileRead the 'exercise_data.json' file from the data directory and display the schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyXlYmnVITPo",
        "outputId": "e15e8d81-29ee-4533-8d6b-cd54032d47b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+-----+----------+\n",
            "|   category| id|price|   product|\n",
            "+-----------+---+-----+----------+\n",
            "|       Food|  1|74.23| Product_1|\n",
            "|   Clothing|  2|42.17| Product_2|\n",
            "|      Books|  3|25.31| Product_3|\n",
            "|Electronics|  4|94.12| Product_4|\n",
            "|       Food|  5|49.59| Product_5|\n",
            "|       Food|  6|40.76| Product_6|\n",
            "|   Clothing|  7|17.78| Product_7|\n",
            "|   Clothing|  8|35.37| Product_8|\n",
            "|      Books|  9|66.37| Product_9|\n",
            "|       Food| 10|88.39|Product_10|\n",
            "|       Food| 11|80.02|Product_11|\n",
            "|      Books| 12| 74.9|Product_12|\n",
            "|       Food| 13|25.59|Product_13|\n",
            "|      Books| 14|20.63|Product_14|\n",
            "|      Books| 15|41.12|Product_15|\n",
            "|Electronics| 16|67.53|Product_16|\n",
            "|   Clothing| 17| 73.8|Product_17|\n",
            "|Electronics| 18|30.49|Product_18|\n",
            "|      Books| 19|34.83|Product_19|\n",
            "|      Books| 20|78.96|Product_20|\n",
            "+-----------+---+-----+----------+\n",
            "only showing top 20 rows\n",
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "df_2 = spark.read \\\n",
        "        .format('json') \\\n",
        "        .option('multiline',True) \\\n",
        "        .load(f\"{data_dir}/exercise_data.json\")\n",
        "\n",
        "df_2.show()\n",
        "df_2.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TPpUGHLITPo"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "### Exercise 3: Write to ParquetWrite the DataFrame from Exercise 1 to a Parquet file named 'output_exercise.parquet' in the data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidllK_GITPo",
        "outputId": "0e6fc186-3db3-4512-f57d-2ebe8c5c973f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n",
            "+---+---------+---+-------+------+\n",
            "| id|     name|age|   city|salary|\n",
            "+---+---------+---+-------+------+\n",
            "|  1| Person_1| 20|Chicago| 85163|\n",
            "|  2| Person_2| 31|Phoenix|118464|\n",
            "|  3| Person_3| 50|Chicago| 94327|\n",
            "|  4| Person_4| 42|     LA|107071|\n",
            "|  5| Person_5| 47|Phoenix|118236|\n",
            "|  6| Person_6| 52|Houston| 60905|\n",
            "|  7| Person_7| 52|    NYC| 51205|\n",
            "|  8| Person_8| 50|Phoenix|106542|\n",
            "|  9| Person_9| 42|     LA| 80638|\n",
            "| 10|Person_10| 31|     LA| 40354|\n",
            "| 11|Person_11| 23|     LA|119110|\n",
            "| 12|Person_12| 44|Chicago| 98678|\n",
            "| 13|Person_13| 37|    NYC| 73709|\n",
            "| 14|Person_14| 43|Houston| 43142|\n",
            "| 15|Person_15| 25|     LA|119299|\n",
            "| 16|Person_16| 54|    NYC| 82376|\n",
            "| 17|Person_17| 32|    NYC|112167|\n",
            "| 18|Person_18| 41|Phoenix| 60096|\n",
            "| 19|Person_19| 50|     LA| 64937|\n",
            "| 20|Person_20| 37|Phoenix| 94970|\n",
            "+---+---------+---+-------+------+\n",
            "only showing top 20 rows\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "df_1.printSchema()\n",
        "df_1.write.parquet(f\"{data_dir}/output_exercise.parquet\",mode=\"overwrite\")\n",
        "df_1.show()\n",
        "df_1.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5GUxOoLITPo"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Great job completing the exercises! Review your solutions and compare them with the solutions notebook if needed.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}