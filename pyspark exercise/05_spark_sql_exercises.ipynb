{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CihtpaykGIT3"
      },
      "source": [
        "# Module 05 - Spark SQL - Exercises\n",
        "\n",
        "## Instructions\n",
        "\n",
        "This notebook contains exercises based on the concepts learned in Module 05.\n",
        "\n",
        "- Complete each exercise in the provided code cells\n",
        "- Run the data setup cells first to generate/create necessary data\n",
        "- Test your solutions by running the verification cells (if provided)\n",
        "- Refer back to the main module notebook if you need help\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pW-DMICGIT4"
      },
      "source": [
        "## Data Setup\n",
        "\n",
        "Run the cells below to set up the data needed for the exercises.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7bTnygbGIT4",
        "outputId": "ba1216dd-9199-4b75-f59d-fc333dce1265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession created successfully!\n",
            "Data directory: /data\n",
            "Employee DataFrame created:\n",
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|  Alice| 25|     Sales| 50000|          NYC|\n",
            "|    Bob| 30|        IT| 60000|           LA|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "|  Diana| 28|        IT| 55000|      Houston|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|\n",
            "|  Grace| 29|        IT| 58000|           LA|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|\n",
            "|   Iris| 26|     Sales| 48000|          NYC|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n",
            "\n",
            "Departments DataFrame created:\n",
            "+----------+-------------+------+\n",
            "|Department|     Location|Budget|\n",
            "+----------+-------------+------+\n",
            "|     Sales|     New York|100000|\n",
            "|        IT|San Francisco|150000|\n",
            "|        HR|      Chicago| 80000|\n",
            "|   Finance|       Boston| 90000|\n",
            "+----------+-------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
        "from pyspark.sql.functions import col, when, lit\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_TOOL_OPTIONS\"] = (\n",
        "    \"--add-opens=java.base/java.lang=ALL-UNNAMED \"\n",
        "    \"--add-opens=java.base/java.nio=ALL-UNNAMED \"\n",
        "    \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\"\n",
        ")\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"python\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\"\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Module 05 Exercises\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Set data directory\n",
        "data_dir = \"../data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "print(\"SparkSession created successfully!\")\n",
        "print(f\"Data directory: {os.path.abspath(data_dir)}\")\n",
        "\n",
        "# Create sample data for Spark SQL exercises\n",
        "data = [\n",
        "    (\"Alice\", 25, \"Sales\", 50000, \"NYC\"),\n",
        "    (\"Bob\", 30, \"IT\", 60000, \"LA\"),\n",
        "    (\"Charlie\", 35, \"Sales\", 70000, \"Chicago\"),\n",
        "    (\"Diana\", 28, \"IT\", 55000, \"Houston\"),\n",
        "    (\"Eve\", 32, \"HR\", 65000, \"Phoenix\"),\n",
        "    (\"Frank\", 27, \"Sales\", 52000, \"NYC\"),\n",
        "    (\"Grace\", 29, \"IT\", 58000, \"LA\"),\n",
        "    (\"Henry\", 31, \"HR\", 62000, \"Chicago\"),\n",
        "    (\"Iris\", 26, \"Sales\", 48000, \"NYC\"),\n",
        "    (\"Jack\", 33, \"IT\", 64000, \"San Francisco\")\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"Name\", StringType(), True),\n",
        "    StructField(\"Age\", IntegerType(), True),\n",
        "    StructField(\"Department\", StringType(), True),\n",
        "    StructField(\"Salary\", IntegerType(), True),\n",
        "    StructField(\"City\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_employees = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Create departments DataFrame\n",
        "departments_data = [\n",
        "    (\"Sales\", \"New York\", 100000),\n",
        "    (\"IT\", \"San Francisco\", 150000),\n",
        "    (\"HR\", \"Chicago\", 80000),\n",
        "    (\"Finance\", \"Boston\", 90000)\n",
        "]\n",
        "\n",
        "departments_schema = StructType([\n",
        "    StructField(\"Department\", StringType(), True),\n",
        "    StructField(\"Location\", StringType(), True),\n",
        "    StructField(\"Budget\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df_departments = spark.createDataFrame(departments_data, departments_schema)\n",
        "\n",
        "print(\"Employee DataFrame created:\")\n",
        "df_employees.show()\n",
        "\n",
        "print(\"\\nDepartments DataFrame created:\")\n",
        "df_departments.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsQ_nFeVGIT5"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "Complete the following exercises based on the concepts from Module 05.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL-jOWNhGIT5"
      },
      "source": [
        "### Exercise 1: Create Temporary View\n",
        "\n",
        "Create a temporary view named 'employees_view' from df_employees using createOrReplaceTempView."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SK42sv3YGIT5"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "df_employees.createOrReplaceTempView(\"employee_view\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bPfLsB-GIT6"
      },
      "source": [
        "### Exercise 2: Basic SQL Query\n",
        "\n",
        "Write a SQL query to select all employees with salary greater than 55000. Display all columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziqJpvAiGIT6",
        "outputId": "27d54914-078f-4152-997c-4be56b5191d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|    Bob| 30|        IT| 60000|           LA|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|  Grace| 29|        IT| 58000|           LA|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT * FROM employee_view\n",
        "                   WHERE Salary > 55000\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmqFweDlGIT6"
      },
      "source": [
        "### Exercise 3: Aggregate SQL Query\n",
        "\n",
        "Write a SQL query to find the average salary by department, ordered by average salary descending."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30giWVLgGIT6",
        "outputId": "38af9aa2-be57-4868-f059-1a947931d5a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+\n",
            "|Department|Avarage_Salary|\n",
            "+----------+--------------+\n",
            "|        HR|       63500.0|\n",
            "|        IT|       59250.0|\n",
            "|     Sales|       55000.0|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT Department,AVG(Salary) AS Avarage_Salary FROM employee_view\n",
        "                   GROUP BY Department\n",
        "                   ORDER BY AVG(Salary) DESC\n",
        "\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbkvFRfKGIT6"
      },
      "source": [
        "### Exercise 4: Create Global Temporary View\n",
        "\n",
        "Create a global temporary view named 'global_employees_view' from df_employees using createOrReplaceGlobalTempView.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m9YrSH_fGIT6"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "df_employees.createOrReplaceGlobalTempView(\"global_employees_view\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prjmb_itGIT7"
      },
      "source": [
        "### Exercise 5: SQL Query with Multiple Conditions\n",
        "\n",
        "Write a SQL query to select employees who are either in the Sales department OR have a salary greater than 60000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRqtSt9vGIT7",
        "outputId": "ba978476-1368-44dc-a837-9dd8e70c4b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|  Alice| 25|     Sales| 50000|          NYC|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|\n",
            "|   Iris| 26|     Sales| 48000|          NYC|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT * from global_temp.global_employees_view\n",
        "                   WHERE Salary>60000 OR Department=='Sales'\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFLGR6g7GIT7"
      },
      "source": [
        "### Exercise 6: SQL Query with ORDER BY\n",
        "\n",
        "Write a SQL query to select all employees, ordered by salary in descending order, then by name in ascending order.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tELuSIMGGIT7",
        "outputId": "ddfcee7e-c46d-4b9f-c779-a8747a6934c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|   Iris| 26|     Sales| 48000|          NYC|\n",
            "|  Alice| 25|     Sales| 50000|          NYC|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|\n",
            "|  Diana| 28|        IT| 55000|      Houston|\n",
            "|  Grace| 29|        IT| 58000|           LA|\n",
            "|    Bob| 30|        IT| 60000|           LA|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"Select * from global_temp.global_employees_view\n",
        "                      Order By salary ASC, Name DESC\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3eybQTvGIT7"
      },
      "source": [
        "### Exercise 7: SQL Query with COUNT and GROUP BY\n",
        "\n",
        "Write a SQL query to count the number of employees in each department.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuOSBJ_6GIT7",
        "outputId": "9b51a060-274a-408f-bb4d-41d262eb80d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+\n",
            "|Department|Employee_count|\n",
            "+----------+--------------+\n",
            "|     Sales|             4|\n",
            "|        HR|             2|\n",
            "|        IT|             4|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"select Department,count(*) As Employee_count\n",
        "                      FROM global_temp.global_employees_view\n",
        "                      GROUP By Department\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xOEBWxiGIT7"
      },
      "source": [
        "### Exercise 8: SQL Query with HAVING Clause\n",
        "\n",
        "Write a SQL query to find departments with an average salary greater than 55000. Show department and average salary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Zxd2rqGIT7",
        "outputId": "9fa909a8-6bfc-4755-8696-1ac623b007f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+\n",
            "|Department|Avarage_Salary|\n",
            "+----------+--------------+\n",
            "|        HR|       63500.0|\n",
            "|        IT|       59250.0|\n",
            "+----------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"select Department,AVG(SALARY) As Avarage_Salary\n",
        "                      FROM global_temp.global_employees_view\n",
        "                      GROUP By Department\n",
        "                      HAVING AVG(SALARY)>55000\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cV30uxVGIT7"
      },
      "source": [
        "### Exercise 9: SQL Query with MIN and MAX\n",
        "\n",
        "Write a SQL query to find the minimum and maximum salary for each department.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFzB3i-RGIT7",
        "outputId": "d6f6dab5-ba4b-4743-f123-43864d67c2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+----------+\n",
            "|Department|min_Salary|max_Salary|\n",
            "+----------+----------+----------+\n",
            "|     Sales|     48000|     70000|\n",
            "|        HR|     62000|     65000|\n",
            "|        IT|     55000|     64000|\n",
            "+----------+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"select Department,MIN(SALARY) As min_Salary ,MAX(SALARY) As max_Salary\n",
        "                      FROM global_temp.global_employees_view\n",
        "                      GROUP By Department\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29PgCA8OGIT7"
      },
      "source": [
        "### Exercise 10: SQL Query with LIKE\n",
        "\n",
        "Write a SQL query to select employees whose name starts with 'A'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ix2TgInGIT7",
        "outputId": "d8fbc731-9cdb-42d5-8804-eb5fa579c297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+------+----+\n",
            "| Name|Age|Department|Salary|City|\n",
            "+-----+---+----------+------+----+\n",
            "|Alice| 25|     Sales| 50000| NYC|\n",
            "+-----+---+----------+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"select *\n",
        "                      FROM global_temp.global_employees_view\n",
        "                      WHERE Name LIKE 'A%'\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAkp1VFpGIT7"
      },
      "source": [
        "### Exercise 11: SQL Query with IN Clause\n",
        "\n",
        "Write a SQL query to select employees whose city is either 'NYC' or 'LA'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shw4WyneGIT7",
        "outputId": "e43d2214-f5fc-4e91-96ae-b21133a98a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+------+----+\n",
            "| Name|Age|Department|Salary|City|\n",
            "+-----+---+----------+------+----+\n",
            "|Alice| 25|     Sales| 50000| NYC|\n",
            "|  Bob| 30|        IT| 60000|  LA|\n",
            "|Frank| 27|     Sales| 52000| NYC|\n",
            "|Grace| 29|        IT| 58000|  LA|\n",
            "| Iris| 26|     Sales| 48000| NYC|\n",
            "+-----+---+----------+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"select *\n",
        "                      FROM global_temp.global_employees_view\n",
        "                      WHERE city IN ('NYC','LA')\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_WHkPEgGIT8"
      },
      "source": [
        "### Exercise 12: SQL Query with CASE Statement\n",
        "\n",
        "Write a SQL query to add a new column 'SalaryCategory' that categorizes salaries: 'High' if salary >= 60000, 'Medium' if salary >= 50000, else 'Low'.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYaWpyRqGIT8",
        "outputId": "ca91b1ae-0a81-44f7-963a-5a53dd1a4903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+-------------+--------------+\n",
            "|   Name|Age|Department|Salary|         City|SalaryCategory|\n",
            "+-------+---+----------+------+-------------+--------------+\n",
            "|  Alice| 25|     Sales| 50000|          NYC|        Medium|\n",
            "|    Bob| 30|        IT| 60000|           LA|          High|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|          High|\n",
            "|  Diana| 28|        IT| 55000|      Houston|        Medium|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|          High|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|        Medium|\n",
            "|  Grace| 29|        IT| 58000|           LA|        Medium|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|          High|\n",
            "|   Iris| 26|     Sales| 48000|          NYC|           Low|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|          High|\n",
            "+-------+---+----------+------+-------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"select *,\n",
        "                             CASE\n",
        "                               WHEN salary >= 60000 THEN 'High'\n",
        "                               WHEN salary >= 50000 THEN 'Medium'\n",
        "                               ELSE 'Low'\n",
        "                             END AS SalaryCategory\n",
        "                       FROM global_temp.global_employees_view\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzNc_oLOGIT8"
      },
      "source": [
        "### Exercise 13: SQL Query with Subquery\n",
        "\n",
        "First, create a view for departments. Then write a SQL query to find employees whose department has a budget greater than 90000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiJBK9IgGIT8",
        "outputId": "cbac9b78-25e8-45b3-d7ad-e53dbd924ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+------+\n",
            "|Department|     Location|Budget|\n",
            "+----------+-------------+------+\n",
            "|        IT|San Francisco|150000|\n",
            "|     Sales|     New York|100000|\n",
            "+----------+-------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# First create departments view\n",
        "df_departments.createOrReplaceTempView(\"Departments\")\n",
        "# Then write your query\n",
        "result = spark.sql(\"\"\"SELECT *\n",
        "                      FROM Departments\n",
        "                      WHERE Department IN (\n",
        "                        SELECT Department\n",
        "                        FROM Departments\n",
        "                        Where Budget>90000\n",
        "                      )\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqO_WqaOGIT8"
      },
      "source": [
        "### Exercise 14: SQL Query with JOIN\n",
        "\n",
        "Create views for both employees and departments. Write a SQL query to join employees with departments on the Department column and show employee name, department, and department location.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5dgYWU_GIT8",
        "outputId": "e9c3c5e9-1b6d-4832-d796-e930c7f19c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------------+\n",
            "|   Name|department|     location|\n",
            "+-------+----------+-------------+\n",
            "|   Iris|     Sales|     New York|\n",
            "|  Frank|     Sales|     New York|\n",
            "|Charlie|     Sales|     New York|\n",
            "|  Alice|     Sales|     New York|\n",
            "|   Jack|        IT|San Francisco|\n",
            "|  Grace|        IT|San Francisco|\n",
            "|  Diana|        IT|San Francisco|\n",
            "|    Bob|        IT|San Francisco|\n",
            "|  Henry|        HR|      Chicago|\n",
            "|    Eve|        HR|      Chicago|\n",
            "|   NULL|   Finance|       Boston|\n",
            "+-------+----------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# Create views first\n",
        "df_departments.createOrReplaceTempView(\"department_view\")\n",
        "df_employees.createOrReplaceTempView(\"employee_view\")\n",
        "# Then write your JOIN query\n",
        "result = spark.sql(\"\"\"SELECT e.Name,d.department,d.location\n",
        "                      FROM employee_view e\n",
        "                      JOIN department_view d\n",
        "                      ON e.department == d.department\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbhD_mYcGIT8"
      },
      "source": [
        "### Exercise 15: SQL Query with SUM\n",
        "\n",
        "Write a SQL query to calculate the total salary for each department.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tUKaHUvGIT8",
        "outputId": "8f055e55-c001-4cee-e134-e098bf8b2e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|TotalSalary|\n",
            "+----------+-----------+\n",
            "|     Sales|     220000|\n",
            "|        HR|     127000|\n",
            "|        IT|     237000|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT Department,SUM(Salary) AS TotalSalary\n",
        "                      FROM employee_view\n",
        "                      GROUP BY Department\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0W1uupUGIT8"
      },
      "source": [
        "### Exercise 16: Convert SQL Result to DataFrame\n",
        "\n",
        "Write a SQL query to select all employees, then convert the result to a DataFrame using spark.table() or by assigning the result directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivxbx6JrGIT8",
        "outputId": "081f8b0b-7cf3-4bde-d67d-43cc223e45c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: <class 'pyspark.sql.classic.dataframe.DataFrame'>\n",
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|  Alice| 25|     Sales| 50000|          NYC|\n",
            "|    Bob| 30|        IT| 60000|           LA|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "|  Diana| 28|        IT| 55000|      Houston|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|\n",
            "|  Grace| 29|        IT| 58000|           LA|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|\n",
            "|   Iris| 26|     Sales| 48000|          NYC|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n",
            "Using Spark.table() function\n",
            "Type: <class 'pyspark.sql.classic.dataframe.DataFrame'>\n",
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|  Alice| 25|     Sales| 50000|          NYC|\n",
            "|    Bob| 30|        IT| 60000|           LA|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "|  Diana| 28|        IT| 55000|      Houston|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|\n",
            "|  Grace| 29|        IT| 58000|           LA|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|\n",
            "|   Iris| 26|     Sales| 48000|          NYC|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# Write SQL query and convert to DataFrame\n",
        "df_result = spark.sql(\"\"\"\n",
        "    Select * From employee_view\n",
        "\"\"\")\n",
        "print(\"Type:\", type(df_result))\n",
        "df_result.show()\n",
        "\n",
        "print(\"Using Spark.table() function\")\n",
        "using_table = spark.table(\"employee_view\")\n",
        "print(\"Type:\", type(using_table))\n",
        "using_table.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7zH3_abGIT8"
      },
      "source": [
        "### Exercise 17: SQL Query with DISTINCT\n",
        "\n",
        "Write a SQL query to find all distinct cities where employees work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCj5s3J8GIT8",
        "outputId": "3f78d948-de06-40eb-bd9c-cd78da19387e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|         city|\n",
            "+-------------+\n",
            "|      Phoenix|\n",
            "|           LA|\n",
            "|      Chicago|\n",
            "|      Houston|\n",
            "|          NYC|\n",
            "|San Francisco|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT DISTINCT city\n",
        "                      FROM employee_view\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM7JZrWNGIT9"
      },
      "source": [
        "### Exercise 18: SQL Query with LIMIT\n",
        "\n",
        "Write a SQL query to select the top 3 employees with the highest salaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRpb6J5YGIT9",
        "outputId": "ec8e7963-461b-41c1-db70-5429ed7a94c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+-------------+\n",
            "|   Name|Age|Department|Salary|         City|\n",
            "+-------+---+----------+------+-------------+\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|\n",
            "+-------+---+----------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT * FROM employee_view\n",
        "                      ORDER BY Salary DESC\n",
        "                      LIMIT 3\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDGqhRrLGIT9"
      },
      "source": [
        "### Exercise 19: SQL Query with Aggregate Functions\n",
        "\n",
        "Write a SQL query to find the count, average, minimum, and maximum salary for each department.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THa1TsJWGIT9",
        "outputId": "9c822811-3e6a-4132-c6df-cda8a7226fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-------------+-------------+-------------+\n",
            "|Department|count(1)|AvarageSalary|MinimumSalary|MaximumSalary|\n",
            "+----------+--------+-------------+-------------+-------------+\n",
            "|     Sales|       4|      55000.0|        48000|        70000|\n",
            "|        HR|       2|      63500.0|        62000|        65000|\n",
            "|        IT|       4|      59250.0|        55000|        64000|\n",
            "+----------+--------+-------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT Department,COUNT(*),AVG(Salary) As AvarageSalary,MIN(Salary) AS MinimumSalary,MAX(Salary) As MaximumSalary\n",
        "                      From employee_view\n",
        "                      GROUP BY Department\n",
        "\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrh07yvoGIT9"
      },
      "source": [
        "### Exercise 20: SQL Query with Window Function (ROW_NUMBER)\n",
        "\n",
        "Write a SQL query to rank employees within each department by salary using ROW_NUMBER() window function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1yh4UlrGIT9",
        "outputId": "0358e199-0b90-4a80-b910-82aff78767d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+-------------+-------+\n",
            "|   Name|Age|Department|Salary|         City|Row_Num|\n",
            "+-------+---+----------+------+-------------+-------+\n",
            "|    Eve| 32|        HR| 65000|      Phoenix|      1|\n",
            "|  Henry| 31|        HR| 62000|      Chicago|      2|\n",
            "|   Jack| 33|        IT| 64000|San Francisco|      1|\n",
            "|    Bob| 30|        IT| 60000|           LA|      2|\n",
            "|  Grace| 29|        IT| 58000|           LA|      3|\n",
            "|  Diana| 28|        IT| 55000|      Houston|      4|\n",
            "|Charlie| 35|     Sales| 70000|      Chicago|      1|\n",
            "|  Frank| 27|     Sales| 52000|          NYC|      2|\n",
            "|  Alice| 25|     Sales| 50000|          NYC|      3|\n",
            "|   Iris| 26|     Sales| 48000|          NYC|      4|\n",
            "+-------+---+----------+------+-------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "result = spark.sql(\"\"\"SELECT *,\n",
        "                      ROW_NUMBER() OVER(partition By Department Order By Salary DESC) As Row_Num\n",
        "                      From employee_view\n",
        "\"\"\")\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WRr2iszGIT9"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Great job completing the exercises! Review your solutions and compare them with the solutions notebook if needed.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}